{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n",
       "0          1    15634602  Hargrave          619    France  Female   42   \n",
       "1          2    15647311      Hill          608     Spain  Female   41   \n",
       "2          3    15619304      Onio          502    France  Female   42   \n",
       "3          4    15701354      Boni          699    France  Female   39   \n",
       "4          5    15737888  Mitchell          850     Spain  Female   43   \n",
       "\n",
       "   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0       2       0.00              1          1               1   \n",
       "1       1   83807.86              1          0               1   \n",
       "2       8  159660.80              3          1               0   \n",
       "3       1       0.00              2          0               0   \n",
       "4       2  125510.82              1          1               1   \n",
       "\n",
       "   EstimatedSalary  Exited  \n",
       "0        101348.88       1  \n",
       "1        112542.58       0  \n",
       "2        113931.57       1  \n",
       "3         93826.63       0  \n",
       "4         79084.10       0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('C:/Users/sahithya/Desktop/archive/Churn_Modelling.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=df.drop(['RowNumber','CustomerId','Surname'],axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CreditScore          int64\n",
       "Geography           object\n",
       "Gender              object\n",
       "Age                  int64\n",
       "Tenure               int64\n",
       "Balance            float64\n",
       "NumOfProducts        int64\n",
       "HasCrCard            int64\n",
       "IsActiveMember       int64\n",
       "EstimatedSalary    float64\n",
       "Exited               int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CreditScore:[619 608 502 699 850 645 822 376 501 684 528 497 476 549 635 616 653 587\n",
      " 726 732 636 510 669 846 577 756 571 574 411 591 533 553 520 722 475 490\n",
      " 804 582 472 465 556 834 660 776 829 637 550 698 585 788 655 601 656 725\n",
      " 511 614 742 687 555 603 751 581 735 661 675 738 813 657 604 519 664 678\n",
      " 757 416 665 777 543 506 493 652 750 729 646 647 808 524 769 730 515 773\n",
      " 814 710 413 623 670 622 785 605 479 685 538 562 721 628 668 828 674 625\n",
      " 432 770 758 795 686 789 589 461 584 579 663 682 793 691 485 650 754 535\n",
      " 716 539 706 586 631 717 800 683 704 615 667 484 480 578 512 606 597 778\n",
      " 514 525 715 580 807 521 759 516 711 618 643 671 689 620 676 572 695 592\n",
      " 567 694 547 594 673 610 767 763 712 703 662 659 523 772 545 634 739 771\n",
      " 681 544 696 766 727 693 557 531 498 651 791 733 811 707 714 782 775 799\n",
      " 602 744 588 747 583 627 731 629 438 642 806 474 559 429 680 749 734 644\n",
      " 626 649 805 718 840 630 654 762 568 613 522 737 648 443 640 540 460 593\n",
      " 801 611 802 745 483 690 492 709 705 560 752 701 537 487 596 702 486 724\n",
      " 548 464 790 534 748 494 590 468 509 818 816 536 753 774 621 569 658 798\n",
      " 641 542 692 639 765 570 638 599 632 779 527 564 833 504 842 508 417 598\n",
      " 741 607 761 848 546 439 755 760 526 713 700 666 566 495 688 612 477 427\n",
      " 839 819 720 459 503 624 529 563 482 796 445 746 786 554 672 787 499 844\n",
      " 450 815 838 803 736 633 600 679 517 792 743 488 421 841 708 507 505 456\n",
      " 435 561 518 565 728 784 552 609 764 697 723 551 444 719 496 541 830 812\n",
      " 677 420 595 617 809 500 826 434 513 478 797 363 399 463 780 452 575 837\n",
      " 794 824 428 823 781 849 489 431 457 768 831 359 820 573 576 558 817 449\n",
      " 440 415 821 530 350 446 425 740 481 783 358 845 451 458 469 423 404 836\n",
      " 473 835 466 491 351 827 843 365 532 414 453 471 401 810 832 470 447 422\n",
      " 825 430 436 426 408 847 418 437 410 454 407 455 462 386 405 383 395 467\n",
      " 433 442 424 448 441 367 412 382 373 419]\n",
      "Geography:['France' 'Spain' 'Germany']\n",
      "Gender:['Female' 'Male']\n",
      "Age:[42 41 39 43 44 50 29 27 31 24 34 25 35 45 58 32 38 46 36 33 40 51 61 49\n",
      " 37 19 66 56 26 21 55 75 22 30 28 65 48 52 57 73 47 54 72 20 67 79 62 53\n",
      " 80 59 68 23 60 70 63 64 18 82 69 74 71 76 77 88 85 84 78 81 92 83]\n",
      "Tenure:[ 2  1  8  7  4  6  3 10  5  9  0]\n",
      "Balance:[     0.    83807.86 159660.8  ...  57369.61  75075.31 130142.79]\n",
      "NumOfProducts:[1 3 2 4]\n",
      "HasCrCard:[1 0]\n",
      "IsActiveMember:[1 0]\n",
      "EstimatedSalary:[101348.88 112542.58 113931.57 ...  42085.58  92888.52  38190.78]\n",
      "Exited:[1 0]\n"
     ]
    }
   ],
   "source": [
    "for col in df1:\n",
    "    print(f'{col}:{df1[col].unique()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.replace({'France':1,'Spain':2,'Germany':3},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       1\n",
       "1       2\n",
       "2       1\n",
       "3       1\n",
       "4       2\n",
       "       ..\n",
       "9995    1\n",
       "9996    1\n",
       "9997    1\n",
       "9998    3\n",
       "9999    1\n",
       "Name: Geography, Length: 10000, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.Geography"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.replace({'Female':1,'Male':0},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       1\n",
       "1       1\n",
       "2       1\n",
       "3       1\n",
       "4       1\n",
       "       ..\n",
       "9995    0\n",
       "9996    0\n",
       "9997    1\n",
       "9998    0\n",
       "9999    1\n",
       "Name: Gender, Length: 10000, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.Gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CreditScore:[619 608 502 699 850 645 822 376 501 684 528 497 476 549 635 616 653 587\n",
      " 726 732 636 510 669 846 577 756 571 574 411 591 533 553 520 722 475 490\n",
      " 804 582 472 465 556 834 660 776 829 637 550 698 585 788 655 601 656 725\n",
      " 511 614 742 687 555 603 751 581 735 661 675 738 813 657 604 519 664 678\n",
      " 757 416 665 777 543 506 493 652 750 729 646 647 808 524 769 730 515 773\n",
      " 814 710 413 623 670 622 785 605 479 685 538 562 721 628 668 828 674 625\n",
      " 432 770 758 795 686 789 589 461 584 579 663 682 793 691 485 650 754 535\n",
      " 716 539 706 586 631 717 800 683 704 615 667 484 480 578 512 606 597 778\n",
      " 514 525 715 580 807 521 759 516 711 618 643 671 689 620 676 572 695 592\n",
      " 567 694 547 594 673 610 767 763 712 703 662 659 523 772 545 634 739 771\n",
      " 681 544 696 766 727 693 557 531 498 651 791 733 811 707 714 782 775 799\n",
      " 602 744 588 747 583 627 731 629 438 642 806 474 559 429 680 749 734 644\n",
      " 626 649 805 718 840 630 654 762 568 613 522 737 648 443 640 540 460 593\n",
      " 801 611 802 745 483 690 492 709 705 560 752 701 537 487 596 702 486 724\n",
      " 548 464 790 534 748 494 590 468 509 818 816 536 753 774 621 569 658 798\n",
      " 641 542 692 639 765 570 638 599 632 779 527 564 833 504 842 508 417 598\n",
      " 741 607 761 848 546 439 755 760 526 713 700 666 566 495 688 612 477 427\n",
      " 839 819 720 459 503 624 529 563 482 796 445 746 786 554 672 787 499 844\n",
      " 450 815 838 803 736 633 600 679 517 792 743 488 421 841 708 507 505 456\n",
      " 435 561 518 565 728 784 552 609 764 697 723 551 444 719 496 541 830 812\n",
      " 677 420 595 617 809 500 826 434 513 478 797 363 399 463 780 452 575 837\n",
      " 794 824 428 823 781 849 489 431 457 768 831 359 820 573 576 558 817 449\n",
      " 440 415 821 530 350 446 425 740 481 783 358 845 451 458 469 423 404 836\n",
      " 473 835 466 491 351 827 843 365 532 414 453 471 401 810 832 470 447 422\n",
      " 825 430 436 426 408 847 418 437 410 454 407 455 462 386 405 383 395 467\n",
      " 433 442 424 448 441 367 412 382 373 419]\n",
      "Geography:[1 2 3]\n",
      "Gender:[1 0]\n",
      "Age:[42 41 39 43 44 50 29 27 31 24 34 25 35 45 58 32 38 46 36 33 40 51 61 49\n",
      " 37 19 66 56 26 21 55 75 22 30 28 65 48 52 57 73 47 54 72 20 67 79 62 53\n",
      " 80 59 68 23 60 70 63 64 18 82 69 74 71 76 77 88 85 84 78 81 92 83]\n",
      "Tenure:[ 2  1  8  7  4  6  3 10  5  9  0]\n",
      "Balance:[     0.    83807.86 159660.8  ...  57369.61  75075.31 130142.79]\n",
      "NumOfProducts:[1 3 2 4]\n",
      "HasCrCard:[1 0]\n",
      "IsActiveMember:[1 0]\n",
      "EstimatedSalary:[101348.88 112542.58 113931.57 ...  42085.58  92888.52  38190.78]\n",
      "Exited:[1 0]\n"
     ]
    }
   ],
   "source": [
    "for col in df1:\n",
    "    print(f'{col}:{df1[col].unique()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CreditScore          int64\n",
       "Geography            int64\n",
       "Gender               int64\n",
       "Age                  int64\n",
       "Tenure               int64\n",
       "Balance            float64\n",
       "NumOfProducts        int64\n",
       "HasCrCard            int64\n",
       "IsActiveMember       int64\n",
       "EstimatedSalary    float64\n",
       "Exited               int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>6504</td>\n",
       "      <td>621</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>168779.47</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5890</td>\n",
       "      <td>482</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>4</td>\n",
       "      <td>124976.19</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>35848.12</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3053</td>\n",
       "      <td>601</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "      <td>5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>27022.57</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6036</td>\n",
       "      <td>674</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>4</td>\n",
       "      <td>79144.34</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>50743.83</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7628</td>\n",
       "      <td>850</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>8</td>\n",
       "      <td>99986.98</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>196582.55</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CreditScore  Geography  Gender  Age  Tenure    Balance  NumOfProducts  \\\n",
       "6504          621          1       0   32       1       0.00              2   \n",
       "5890          482          1       0   38       4  124976.19              1   \n",
       "3053          601          1       1   34       5       0.00              2   \n",
       "6036          674          1       1   27       4   79144.34              1   \n",
       "7628          850          1       0   28       8   99986.98              1   \n",
       "\n",
       "      HasCrCard  IsActiveMember  EstimatedSalary  Exited  \n",
       "6504          1               1        168779.47       0  \n",
       "5890          1               0         35848.12       0  \n",
       "3053          1               0         27022.57       0  \n",
       "6036          0               1         50743.83       0  \n",
       "7628          1               0        196582.55       0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=df1.drop('Exited',axis='columns')\n",
    "y=df1['Exited']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "383\n"
     ]
    }
   ],
   "source": [
    "count=0\n",
    "for ele in y_test:\n",
    "    if ele==1:\n",
    "        count=count+1\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1654\n"
     ]
    }
   ],
   "source": [
    "count=0\n",
    "for ele in y_train:\n",
    "    if ele==1:\n",
    "        count=count+1\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8000, 10)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 10)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=keras.Sequential([\n",
    "           keras.layers.Dense(8,input_shape=(10,),activation='relu'),\n",
    "           keras.layers.Dense(8,activation='relu'),\n",
    "           keras.layers.Dense(8,activation='relu'),\n",
    "           keras.layers.Dense(1,activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer='sgd',\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8000 samples\n",
      "Epoch 1/150\n",
      "8000/8000 [==============================] - 1s 83us/sample - loss: 0.5095 - accuracy: 0.7933\n",
      "Epoch 2/150\n",
      "8000/8000 [==============================] - 1s 79us/sample - loss: 0.5095 - accuracy: 0.7933\n",
      "Epoch 3/150\n",
      "8000/8000 [==============================] - 1s 74us/sample - loss: 0.5095 - accuracy: 0.7933\n",
      "Epoch 4/150\n",
      "8000/8000 [==============================] - 1s 76us/sample - loss: 0.5095 - accuracy: 0.7933\n",
      "Epoch 5/150\n",
      "8000/8000 [==============================] - 1s 75us/sample - loss: 0.5095 - accuracy: 0.7933\n",
      "Epoch 6/150\n",
      "8000/8000 [==============================] - 1s 74us/sample - loss: 0.5095 - accuracy: 0.7933\n",
      "Epoch 7/150\n",
      "8000/8000 [==============================] - 1s 82us/sample - loss: 0.5095 - accuracy: 0.7933\n",
      "Epoch 8/150\n",
      "8000/8000 [==============================] - 1s 82us/sample - loss: 0.5095 - accuracy: 0.7933\n",
      "Epoch 9/150\n",
      "8000/8000 [==============================] - 1s 85us/sample - loss: 0.5095 - accuracy: 0.7933\n",
      "Epoch 10/150\n",
      "8000/8000 [==============================] - 1s 76us/sample - loss: 0.5095 - accuracy: 0.7933\n",
      "Epoch 11/150\n",
      "8000/8000 [==============================] - 1s 75us/sample - loss: 0.5095 - accuracy: 0.7933\n",
      "Epoch 12/150\n",
      "8000/8000 [==============================] - 1s 75us/sample - loss: 0.5095 - accuracy: 0.7933\n",
      "Epoch 13/150\n",
      "8000/8000 [==============================] - 1s 76us/sample - loss: 0.5095 - accuracy: 0.7933\n",
      "Epoch 14/150\n",
      "8000/8000 [==============================] - 1s 74us/sample - loss: 0.5095 - accuracy: 0.7933\n",
      "Epoch 15/150\n",
      "8000/8000 [==============================] - 1s 76us/sample - loss: 0.5095 - accuracy: 0.7933\n",
      "Epoch 16/150\n",
      "8000/8000 [==============================] - 1s 86us/sample - loss: 0.5095 - accuracy: 0.7933\n",
      "Epoch 17/150\n",
      "8000/8000 [==============================] - 1s 76us/sample - loss: 0.5095 - accuracy: 0.7933\n",
      "Epoch 18/150\n",
      "8000/8000 [==============================] - 1s 86us/sample - loss: 0.5095 - accuracy: 0.7933\n",
      "Epoch 19/150\n",
      "8000/8000 [==============================] - 1s 77us/sample - loss: 0.5095 - accuracy: 0.7933\n",
      "Epoch 20/150\n",
      "8000/8000 [==============================] - 1s 74us/sample - loss: 0.5095 - accuracy: 0.7933\n",
      "Epoch 21/150\n",
      "8000/8000 [==============================] - 1s 74us/sample - loss: 0.5095 - accuracy: 0.7933\n",
      "Epoch 22/150\n",
      "8000/8000 [==============================] - 1s 75us/sample - loss: 0.5095 - accuracy: 0.7933\n",
      "Epoch 23/150\n",
      "8000/8000 [==============================] - 1s 75us/sample - loss: 0.5095 - accuracy: 0.7933\n",
      "Epoch 24/150\n",
      "8000/8000 [==============================] - 1s 75us/sample - loss: 0.5095 - accuracy: 0.7933\n",
      "Epoch 25/150\n",
      "8000/8000 [==============================] - 1s 88us/sample - loss: 0.5095 - accuracy: 0.7933\n",
      "Epoch 26/150\n",
      "8000/8000 [==============================] - 1s 80us/sample - loss: 0.5095 - accuracy: 0.7933\n",
      "Epoch 27/150\n",
      "8000/8000 [==============================] - 1s 79us/sample - loss: 0.5095 - accuracy: 0.7933\n",
      "Epoch 28/150\n",
      "8000/8000 [==============================] - 1s 73us/sample - loss: 0.5095 - accuracy: 0.7933\n",
      "Epoch 29/150\n",
      "8000/8000 [==============================] - 1s 74us/sample - loss: 0.5095 - accuracy: 0.7933\n",
      "Epoch 30/150\n",
      "8000/8000 [==============================] - 1s 74us/sample - loss: 0.5095 - accuracy: 0.7933\n",
      "Epoch 31/150\n",
      "8000/8000 [==============================] - 1s 75us/sample - loss: 0.5095 - accuracy: 0.7933\n",
      "Epoch 32/150\n",
      "8000/8000 [==============================] - 1s 74us/sample - loss: 0.5095 - accuracy: 0.7933\n",
      "Epoch 33/150\n",
      "8000/8000 [==============================] - 1s 71us/sample - loss: 0.5095 - accuracy: 0.7933\n",
      "Epoch 34/150\n",
      "8000/8000 [==============================] - 1s 83us/sample - loss: 0.5095 - accuracy: 0.7933\n",
      "Epoch 35/150\n",
      "8000/8000 [==============================] - 1s 91us/sample - loss: 0.5095 - accuracy: 0.7933\n",
      "Epoch 36/150\n",
      "8000/8000 [==============================] - 1s 81us/sample - loss: 0.5095 - accuracy: 0.7933\n",
      "Epoch 37/150\n",
      "8000/8000 [==============================] - 1s 72us/sample - loss: 0.5095 - accuracy: 0.7933\n",
      "Epoch 38/150\n",
      "8000/8000 [==============================] - 1s 74us/sample - loss: 0.5095 - accuracy: 0.7933\n",
      "Epoch 39/150\n",
      "8000/8000 [==============================] - 1s 73us/sample - loss: 0.5095 - accuracy: 0.7933\n",
      "Epoch 40/150\n",
      "8000/8000 [==============================] - 1s 73us/sample - loss: 0.5095 - accuracy: 0.7933\n",
      "Epoch 41/150\n",
      "8000/8000 [==============================] - 1s 74us/sample - loss: 0.5095 - accuracy: 0.7933\n",
      "Epoch 42/150\n",
      "8000/8000 [==============================] - 1s 74us/sample - loss: 0.5095 - accuracy: 0.7933\n",
      "Epoch 43/150\n",
      "8000/8000 [==============================] - 1s 86us/sample - loss: 0.5095 - accuracy: 0.7933\n",
      "Epoch 44/150\n",
      "8000/8000 [==============================] - 1s 79us/sample - loss: 0.5095 - accuracy: 0.7933\n",
      "Epoch 45/150\n",
      "8000/8000 [==============================] - 1s 83us/sample - loss: 0.5095 - accuracy: 0.7933\n",
      "Epoch 46/150\n",
      "8000/8000 [==============================] - 1s 77us/sample - loss: 0.5095 - accuracy: 0.7933\n",
      "Epoch 47/150\n",
      "8000/8000 [==============================] - 1s 72us/sample - loss: 0.5095 - accuracy: 0.7933\n",
      "Epoch 48/150\n",
      "8000/8000 [==============================] - 1s 74us/sample - loss: 0.5095 - accuracy: 0.7933\n",
      "Epoch 49/150\n",
      "8000/8000 [==============================] - 1s 72us/sample - loss: 0.5095 - accuracy: 0.7933\n",
      "Epoch 50/150\n",
      "8000/8000 [==============================] - 1s 73us/sample - loss: 0.5095 - accuracy: 0.7933\n",
      "Epoch 51/150\n",
      "8000/8000 [==============================] - 1s 72us/sample - loss: 0.5095 - accuracy: 0.7933\n",
      "Epoch 52/150\n",
      "8000/8000 [==============================] - 1s 90us/sample - loss: 0.5095 - accuracy: 0.7933\n",
      "Epoch 53/150\n",
      "8000/8000 [==============================] - 1s 85us/sample - loss: 0.5095 - accuracy: 0.7933\n",
      "Epoch 54/150\n",
      "8000/8000 [==============================] - 1s 78us/sample - loss: 0.5095 - accuracy: 0.7933\n",
      "Epoch 55/150\n",
      "8000/8000 [==============================] - 1s 73us/sample - loss: 0.5095 - accuracy: 0.7933\n",
      "Epoch 56/150\n",
      "8000/8000 [==============================] - 1s 73us/sample - loss: 0.5095 - accuracy: 0.7933\n",
      "Epoch 57/150\n",
      "8000/8000 [==============================] - 1s 74us/sample - loss: 0.5095 - accuracy: 0.7933\n",
      "Epoch 58/150\n",
      "8000/8000 [==============================] - 1s 74us/sample - loss: 0.5095 - accuracy: 0.7933\n",
      "Epoch 59/150\n",
      "8000/8000 [==============================] - 1s 74us/sample - loss: 0.5095 - accuracy: 0.7933\n",
      "Epoch 60/150\n",
      "8000/8000 [==============================] - 1s 77us/sample - loss: 0.5095 - accuracy: 0.7933\n",
      "Epoch 61/150\n",
      "8000/8000 [==============================] - 1s 83us/sample - loss: 0.5095 - accuracy: 0.7933\n",
      "Epoch 62/150\n",
      "8000/8000 [==============================] - 1s 87us/sample - loss: 0.5095 - accuracy: 0.7933\n",
      "Epoch 63/150\n",
      "8000/8000 [==============================] - 1s 78us/sample - loss: 0.5095 - accuracy: 0.7933\n",
      "Epoch 64/150\n",
      "8000/8000 [==============================] - 1s 75us/sample - loss: 0.5095 - accuracy: 0.7933\n",
      "Epoch 65/150\n",
      "8000/8000 [==============================] - 1s 73us/sample - loss: 0.5095 - accuracy: 0.7933\n",
      "Epoch 66/150\n",
      "8000/8000 [==============================] - 1s 70us/sample - loss: 0.5095 - accuracy: 0.7933\n",
      "Epoch 67/150\n",
      "8000/8000 [==============================] - 1s 74us/sample - loss: 0.5095 - accuracy: 0.7933\n",
      "Epoch 68/150\n",
      "8000/8000 [==============================] - 1s 73us/sample - loss: 0.5095 - accuracy: 0.7933\n",
      "Epoch 69/150\n",
      "8000/8000 [==============================] - 1s 79us/sample - loss: 0.5095 - accuracy: 0.7933\n",
      "Epoch 70/150\n",
      "8000/8000 [==============================] - 1s 82us/sample - loss: 0.5095 - accuracy: 0.7933\n",
      "Epoch 71/150\n",
      "8000/8000 [==============================] - 1s 83us/sample - loss: 0.5095 - accuracy: 0.7933\n",
      "Epoch 72/150\n",
      "8000/8000 [==============================] - 1s 78us/sample - loss: 0.5095 - accuracy: 0.7933\n",
      "Epoch 73/150\n",
      "8000/8000 [==============================] - 1s 71us/sample - loss: 0.5095 - accuracy: 0.7933\n",
      "Epoch 74/150\n",
      "8000/8000 [==============================] - 1s 76us/sample - loss: 0.5095 - accuracy: 0.7933\n",
      "Epoch 75/150\n",
      "8000/8000 [==============================] - 1s 74us/sample - loss: 0.5095 - accuracy: 0.7933\n",
      "Epoch 76/150\n",
      "8000/8000 [==============================] - 1s 72us/sample - loss: 0.5095 - accuracy: 0.7933\n",
      "Epoch 77/150\n",
      "8000/8000 [==============================] - 1s 73us/sample - loss: 0.5095 - accuracy: 0.7933\n",
      "Epoch 78/150\n",
      "8000/8000 [==============================] - 1s 79us/sample - loss: 0.5095 - accuracy: 0.7933\n",
      "Epoch 79/150\n",
      "8000/8000 [==============================] - 1s 86us/sample - loss: 0.5095 - accuracy: 0.7933\n",
      "Epoch 80/150\n",
      "8000/8000 [==============================] - 1s 84us/sample - loss: 0.5095 - accuracy: 0.7933\n",
      "Epoch 81/150\n",
      "8000/8000 [==============================] - 1s 76us/sample - loss: 0.5095 - accuracy: 0.7933\n",
      "Epoch 82/150\n",
      "8000/8000 [==============================] - 1s 75us/sample - loss: 0.5095 - accuracy: 0.7933\n",
      "Epoch 83/150\n",
      "8000/8000 [==============================] - 1s 73us/sample - loss: 0.5095 - accuracy: 0.7933\n",
      "Epoch 84/150\n",
      "8000/8000 [==============================] - 1s 72us/sample - loss: 0.5095 - accuracy: 0.7933\n",
      "Epoch 85/150\n",
      "8000/8000 [==============================] - 1s 73us/sample - loss: 0.5095 - accuracy: 0.7933\n",
      "Epoch 86/150\n",
      "8000/8000 [==============================] - 1s 75us/sample - loss: 0.5095 - accuracy: 0.7933\n",
      "Epoch 87/150\n",
      "8000/8000 [==============================] - 1s 73us/sample - loss: 0.5095 - accuracy: 0.7933\n",
      "Epoch 88/150\n",
      "8000/8000 [==============================] - 1s 82us/sample - loss: 0.5095 - accuracy: 0.7933\n",
      "Epoch 89/150\n",
      "8000/8000 [==============================] - 1s 81us/sample - loss: 0.5095 - accuracy: 0.7933\n",
      "Epoch 90/150\n",
      "8000/8000 [==============================] - 1s 74us/sample - loss: 0.5095 - accuracy: 0.7933\n",
      "Epoch 91/150\n",
      "8000/8000 [==============================] - 1s 73us/sample - loss: 0.5095 - accuracy: 0.7933\n",
      "Epoch 92/150\n",
      "8000/8000 [==============================] - 1s 72us/sample - loss: 0.5095 - accuracy: 0.7933\n",
      "Epoch 93/150\n",
      "8000/8000 [==============================] - 1s 73us/sample - loss: 0.5095 - accuracy: 0.7933\n",
      "Epoch 94/150\n",
      "8000/8000 [==============================] - 1s 73us/sample - loss: 0.5095 - accuracy: 0.7933\n",
      "Epoch 95/150\n",
      "8000/8000 [==============================] - 1s 72us/sample - loss: 0.5095 - accuracy: 0.7933\n",
      "Epoch 96/150\n",
      "8000/8000 [==============================] - 1s 71us/sample - loss: 0.5095 - accuracy: 0.7933\n",
      "Epoch 97/150\n",
      "8000/8000 [==============================] - 1s 84us/sample - loss: 0.5095 - accuracy: 0.7933\n",
      "Epoch 98/150\n",
      "8000/8000 [==============================] - 1s 83us/sample - loss: 0.5095 - accuracy: 0.7933\n",
      "Epoch 99/150\n",
      "8000/8000 [==============================] - 1s 77us/sample - loss: 0.5095 - accuracy: 0.7933\n",
      "Epoch 100/150\n",
      "8000/8000 [==============================] - 1s 73us/sample - loss: 0.5095 - accuracy: 0.7933\n",
      "Epoch 101/150\n",
      "8000/8000 [==============================] - 1s 73us/sample - loss: 0.5095 - accuracy: 0.7933\n",
      "Epoch 102/150\n",
      "8000/8000 [==============================] - 1s 73us/sample - loss: 0.5095 - accuracy: 0.7933\n",
      "Epoch 103/150\n",
      "8000/8000 [==============================] - 1s 73us/sample - loss: 0.5095 - accuracy: 0.7933\n",
      "Epoch 104/150\n",
      "8000/8000 [==============================] - 1s 74us/sample - loss: 0.5095 - accuracy: 0.7933\n",
      "Epoch 105/150\n",
      "8000/8000 [==============================] - 1s 79us/sample - loss: 0.5095 - accuracy: 0.7933\n",
      "Epoch 106/150\n",
      "8000/8000 [==============================] - 1s 83us/sample - loss: 0.5095 - accuracy: 0.7933\n",
      "Epoch 107/150\n",
      "8000/8000 [==============================] - 1s 81us/sample - loss: 0.5095 - accuracy: 0.7933\n",
      "Epoch 108/150\n",
      "8000/8000 [==============================] - 1s 77us/sample - loss: 0.5095 - accuracy: 0.7933\n",
      "Epoch 109/150\n",
      "8000/8000 [==============================] - 1s 73us/sample - loss: 0.5095 - accuracy: 0.7933\n",
      "Epoch 110/150\n",
      "8000/8000 [==============================] - 1s 74us/sample - loss: 0.5095 - accuracy: 0.7933\n",
      "Epoch 111/150\n",
      "8000/8000 [==============================] - 1s 74us/sample - loss: 0.5095 - accuracy: 0.7933\n",
      "Epoch 112/150\n",
      "8000/8000 [==============================] - 1s 72us/sample - loss: 0.5095 - accuracy: 0.7933\n",
      "Epoch 113/150\n",
      "8000/8000 [==============================] - 1s 73us/sample - loss: 0.5095 - accuracy: 0.7933\n",
      "Epoch 114/150\n",
      "8000/8000 [==============================] - 1s 78us/sample - loss: 0.5095 - accuracy: 0.7933\n",
      "Epoch 115/150\n",
      "8000/8000 [==============================] - 1s 83us/sample - loss: 0.5095 - accuracy: 0.7933\n",
      "Epoch 116/150\n",
      "8000/8000 [==============================] - 1s 81us/sample - loss: 0.5095 - accuracy: 0.7933\n",
      "Epoch 117/150\n",
      "8000/8000 [==============================] - 1s 78us/sample - loss: 0.5095 - accuracy: 0.7933\n",
      "Epoch 118/150\n",
      "8000/8000 [==============================] - 1s 72us/sample - loss: 0.5095 - accuracy: 0.7933\n",
      "Epoch 119/150\n",
      "8000/8000 [==============================] - 1s 70us/sample - loss: 0.5095 - accuracy: 0.7933\n",
      "Epoch 120/150\n",
      "8000/8000 [==============================] - 1s 75us/sample - loss: 0.5095 - accuracy: 0.7933\n",
      "Epoch 121/150\n",
      "8000/8000 [==============================] - 1s 73us/sample - loss: 0.5095 - accuracy: 0.7933\n",
      "Epoch 122/150\n",
      "8000/8000 [==============================] - 1s 74us/sample - loss: 0.5095 - accuracy: 0.7933\n",
      "Epoch 123/150\n",
      "8000/8000 [==============================] - 1s 73us/sample - loss: 0.5095 - accuracy: 0.7933\n",
      "Epoch 124/150\n",
      "8000/8000 [==============================] - 1s 84us/sample - loss: 0.5095 - accuracy: 0.7933\n",
      "Epoch 125/150\n",
      "8000/8000 [==============================] - 1s 85us/sample - loss: 0.5095 - accuracy: 0.7933\n",
      "Epoch 126/150\n",
      "8000/8000 [==============================] - 1s 78us/sample - loss: 0.5095 - accuracy: 0.7933\n",
      "Epoch 127/150\n",
      "8000/8000 [==============================] - 1s 73us/sample - loss: 0.5095 - accuracy: 0.7933\n",
      "Epoch 128/150\n",
      "8000/8000 [==============================] - 1s 70us/sample - loss: 0.5095 - accuracy: 0.7933\n",
      "Epoch 129/150\n",
      "8000/8000 [==============================] - 1s 73us/sample - loss: 0.5095 - accuracy: 0.7933\n",
      "Epoch 130/150\n",
      "8000/8000 [==============================] - 1s 72us/sample - loss: 0.5095 - accuracy: 0.7933\n",
      "Epoch 131/150\n",
      "8000/8000 [==============================] - 1s 74us/sample - loss: 0.5095 - accuracy: 0.7933\n",
      "Epoch 132/150\n",
      "8000/8000 [==============================] - 1s 74us/sample - loss: 0.5095 - accuracy: 0.7933\n",
      "Epoch 133/150\n",
      "8000/8000 [==============================] - 1s 84us/sample - loss: 0.5095 - accuracy: 0.7933\n",
      "Epoch 134/150\n",
      "8000/8000 [==============================] - 1s 80us/sample - loss: 0.5095 - accuracy: 0.7933\n",
      "Epoch 135/150\n",
      "8000/8000 [==============================] - 1s 79us/sample - loss: 0.5095 - accuracy: 0.7933\n",
      "Epoch 136/150\n",
      "8000/8000 [==============================] - 1s 76us/sample - loss: 0.5095 - accuracy: 0.7933\n",
      "Epoch 137/150\n",
      "8000/8000 [==============================] - 1s 74us/sample - loss: 0.5095 - accuracy: 0.7933\n",
      "Epoch 138/150\n",
      "8000/8000 [==============================] - 1s 72us/sample - loss: 0.5095 - accuracy: 0.7933\n",
      "Epoch 139/150\n",
      "8000/8000 [==============================] - 1s 72us/sample - loss: 0.5095 - accuracy: 0.7933\n",
      "Epoch 140/150\n",
      "8000/8000 [==============================] - 1s 72us/sample - loss: 0.5095 - accuracy: 0.7933\n",
      "Epoch 141/150\n",
      "8000/8000 [==============================] - 1s 74us/sample - loss: 0.5095 - accuracy: 0.7933\n",
      "Epoch 142/150\n",
      "8000/8000 [==============================] - 1s 85us/sample - loss: 0.5095 - accuracy: 0.7933\n",
      "Epoch 143/150\n",
      "8000/8000 [==============================] - 1s 82us/sample - loss: 0.5095 - accuracy: 0.7933\n",
      "Epoch 144/150\n",
      "8000/8000 [==============================] - 1s 79us/sample - loss: 0.5095 - accuracy: 0.7933\n",
      "Epoch 145/150\n",
      "8000/8000 [==============================] - 1s 74us/sample - loss: 0.5095 - accuracy: 0.7933\n",
      "Epoch 146/150\n",
      "8000/8000 [==============================] - 1s 98us/sample - loss: 0.5095 - accuracy: 0.7933\n",
      "Epoch 147/150\n",
      "8000/8000 [==============================] - 1s 78us/sample - loss: 0.5095 - accuracy: 0.7933\n",
      "Epoch 148/150\n",
      "8000/8000 [==============================] - 1s 73us/sample - loss: 0.5095 - accuracy: 0.7933\n",
      "Epoch 149/150\n",
      "8000/8000 [==============================] - 1s 70us/sample - loss: 0.5095 - accuracy: 0.7933\n",
      "Epoch 150/150\n",
      "8000/8000 [==============================] - 1s 80us/sample - loss: 0.5095 - accuracy: 0.7933\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2a8f33ecdc8>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train,y_train,epochs=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000/2000 [==============================] - 0s 50us/sample - loss: 0.4891 - accuracy: 0.8085\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.4891185255050659, 0.8085]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.20680836],\n",
       "       [0.20680836],\n",
       "       [0.20680836],\n",
       "       [0.20680836],\n",
       "       [0.20680836]], dtype=float32)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yp=model.predict(x_test)\n",
    "yp[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7878    1\n",
       "3224    1\n",
       "1919    1\n",
       "4432    0\n",
       "4835    0\n",
       "Name: Exited, dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=[]\n",
    "for element in yp:\n",
    "    if element>0.5:\n",
    "        y_pred.append(1)\n",
    "    if element<0.5:\n",
    "        y_pred.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7878    1\n",
       "3224    1\n",
       "1919    1\n",
       "4432    0\n",
       "4835    0\n",
       "4895    0\n",
       "7269    1\n",
       "1451    0\n",
       "1742    1\n",
       "4628    0\n",
       "Name: Exited, dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      1.00      0.89      1617\n",
      "           1       0.00      0.00      0.00       383\n",
      "\n",
      "    accuracy                           0.81      2000\n",
      "   macro avg       0.40      0.50      0.45      2000\n",
      "weighted avg       0.65      0.81      0.72      2000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sahithya\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix , classification_report\n",
    "print(classification_report(y_test,y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%matplotlib.inline` not found.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib.inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(69.0, 0.5, 'Truth')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sn\n",
    "cm = tf.math.confusion_matrix(labels=y_test,predictions=y_pred)\n",
    "\n",
    "plt.figure(figsize = (10,7))\n",
    "sn.heatmap(cm, annot=True, fmt='d')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Truth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ANN(X_train, y_train, X_test, y_test, loss, weights):\n",
    "    model = keras.Sequential([\n",
    "        keras.layers.Dense(10, input_dim=10, activation='relu'),\n",
    "        keras.layers.Dense(15, activation='relu'),\n",
    "        keras.layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer='adam', loss=loss, metrics=['accuracy'])\n",
    "    \n",
    "    if weights == -1:\n",
    "        model.fit(X_train, y_train, epochs=100)\n",
    "    else:\n",
    "        model.fit(X_train, y_train, epochs=100, class_weight = weights)\n",
    "    \n",
    "    print(model.evaluate(X_test, y_test))\n",
    "    \n",
    "    y_preds = model.predict(X_test)\n",
    "    y_preds = np.round(y_preds)\n",
    "    \n",
    "    print(\"Classification Report: \\n\", classification_report(y_test, y_preds))\n",
    "    \n",
    "    return y_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# method_1---->Randomly_under_sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_class_0,count_class_1=df['Exited'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2_class_0=df1[df1['Exited']==0]\n",
    "df2_class_1=df1[df1['Exited']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>608</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>699</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>850</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>822</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>7</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10062.80</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>501</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>4</td>\n",
       "      <td>142051.07</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>74940.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9993</td>\n",
       "      <td>644</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>7</td>\n",
       "      <td>155060.41</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>29179.52</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9994</td>\n",
       "      <td>800</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>167773.55</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9995</td>\n",
       "      <td>771</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>96270.64</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9996</td>\n",
       "      <td>516</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>10</td>\n",
       "      <td>57369.61</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101699.77</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9999</td>\n",
       "      <td>792</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>130142.79</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38190.78</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7963 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      CreditScore  Geography  Gender  Age  Tenure    Balance  NumOfProducts  \\\n",
       "1             608          2       1   41       1   83807.86              1   \n",
       "3             699          1       1   39       1       0.00              2   \n",
       "4             850          2       1   43       2  125510.82              1   \n",
       "6             822          1       0   50       7       0.00              2   \n",
       "8             501          1       0   44       4  142051.07              2   \n",
       "...           ...        ...     ...  ...     ...        ...            ...   \n",
       "9993          644          1       0   28       7  155060.41              1   \n",
       "9994          800          1       1   29       2       0.00              2   \n",
       "9995          771          1       0   39       5       0.00              2   \n",
       "9996          516          1       0   35      10   57369.61              1   \n",
       "9999          792          1       1   28       4  130142.79              1   \n",
       "\n",
       "      HasCrCard  IsActiveMember  EstimatedSalary  Exited  \n",
       "1             0               1        112542.58       0  \n",
       "3             0               0         93826.63       0  \n",
       "4             1               1         79084.10       0  \n",
       "6             1               1         10062.80       0  \n",
       "8             0               1         74940.50       0  \n",
       "...         ...             ...              ...     ...  \n",
       "9993          1               0         29179.52       0  \n",
       "9994          0               0        167773.55       0  \n",
       "9995          1               0         96270.64       0  \n",
       "9996          1               1        101699.77       0  \n",
       "9999          1               0         38190.78       0  \n",
       "\n",
       "[7963 rows x 11 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2_class_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>619</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>502</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>645</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>8</td>\n",
       "      <td>113755.78</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>149756.71</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>376</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>4</td>\n",
       "      <td>115046.74</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>119346.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>653</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>58</td>\n",
       "      <td>1</td>\n",
       "      <td>132602.88</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5097.67</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9981</td>\n",
       "      <td>498</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>3</td>\n",
       "      <td>152039.70</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>53445.17</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9982</td>\n",
       "      <td>655</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>46</td>\n",
       "      <td>7</td>\n",
       "      <td>137145.12</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>115146.40</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9991</td>\n",
       "      <td>597</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>53</td>\n",
       "      <td>4</td>\n",
       "      <td>88381.21</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>69384.71</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9997</td>\n",
       "      <td>709</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "      <td>7</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>42085.58</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9998</td>\n",
       "      <td>772</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>3</td>\n",
       "      <td>75075.31</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>92888.52</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2037 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      CreditScore  Geography  Gender  Age  Tenure    Balance  NumOfProducts  \\\n",
       "0             619          1       1   42       2       0.00              1   \n",
       "2             502          1       1   42       8  159660.80              3   \n",
       "5             645          2       0   44       8  113755.78              2   \n",
       "7             376          3       1   29       4  115046.74              4   \n",
       "16            653          3       0   58       1  132602.88              1   \n",
       "...           ...        ...     ...  ...     ...        ...            ...   \n",
       "9981          498          3       0   42       3  152039.70              1   \n",
       "9982          655          3       1   46       7  137145.12              1   \n",
       "9991          597          1       1   53       4   88381.21              1   \n",
       "9997          709          1       1   36       7       0.00              1   \n",
       "9998          772          3       0   42       3   75075.31              2   \n",
       "\n",
       "      HasCrCard  IsActiveMember  EstimatedSalary  Exited  \n",
       "0             1               1        101348.88       1  \n",
       "2             1               0        113931.57       1  \n",
       "5             1               0        149756.71       1  \n",
       "7             1               0        119346.88       1  \n",
       "16            1               0          5097.67       1  \n",
       "...         ...             ...              ...     ...  \n",
       "9981          1               1         53445.17       1  \n",
       "9982          1               0        115146.40       1  \n",
       "9991          1               0         69384.71       1  \n",
       "9997          0               1         42085.58       1  \n",
       "9998          1               0         92888.52       1  \n",
       "\n",
       "[2037 rows x 11 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2_class_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7963, 11)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2_class_0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2037, 11)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2_class_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_class_0_under=df2_class_0.sample(count_class_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4074, 11)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_under=pd.concat([df_class_0_under,df2_class_1],axis=0)\n",
    "df_test_under.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random_under_sampling\n",
      "1    2037\n",
      "0    2037\n",
      "Name: Exited, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print('Random_under_sampling')\n",
    "print(df_test_under.Exited.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=df_test_under.drop('Exited',axis='columns')\n",
    "y=df_test_under['Exited']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=5,stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1630\n",
       "1    1629\n",
       "Name: Exited, dtype: int64"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    408\n",
       "0    407\n",
       "Name: Exited, dtype: int64"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3259 samples\n",
      "Epoch 1/100\n",
      "3259/3259 [==============================] - 1s 419us/sample - loss: 4556.8895 - accuracy: 0.5428\n",
      "Epoch 2/100\n",
      "3259/3259 [==============================] - 0s 88us/sample - loss: 798.3297 - accuracy: 0.5443\n",
      "Epoch 3/100\n",
      "3259/3259 [==============================] - 0s 103us/sample - loss: 186.7686 - accuracy: 0.5453\n",
      "Epoch 4/100\n",
      "3259/3259 [==============================] - 0s 90us/sample - loss: 69.2096 - accuracy: 0.5308\n",
      "Epoch 5/100\n",
      "3259/3259 [==============================] - 0s 102us/sample - loss: 92.0136 - accuracy: 0.5149\n",
      "Epoch 6/100\n",
      "3259/3259 [==============================] - 0s 99us/sample - loss: 68.8656 - accuracy: 0.5456\n",
      "Epoch 7/100\n",
      "3259/3259 [==============================] - 0s 88us/sample - loss: 68.2488 - accuracy: 0.5419\n",
      "Epoch 8/100\n",
      "3259/3259 [==============================] - 0s 89us/sample - loss: 29.1630 - accuracy: 0.5431\n",
      "Epoch 9/100\n",
      "3259/3259 [==============================] - 0s 92us/sample - loss: 31.0066 - accuracy: 0.5443\n",
      "Epoch 10/100\n",
      "3259/3259 [==============================] - 0s 91us/sample - loss: 33.0078 - accuracy: 0.5302\n",
      "Epoch 11/100\n",
      "3259/3259 [==============================] - 0s 89us/sample - loss: 48.8988 - accuracy: 0.5210\n",
      "Epoch 12/100\n",
      "3259/3259 [==============================] - 0s 91us/sample - loss: 39.7361 - accuracy: 0.5152\n",
      "Epoch 13/100\n",
      "3259/3259 [==============================] - 0s 94us/sample - loss: 40.6205 - accuracy: 0.5296\n",
      "Epoch 14/100\n",
      "3259/3259 [==============================] - 0s 90us/sample - loss: 33.3352 - accuracy: 0.5173\n",
      "Epoch 15/100\n",
      "3259/3259 [==============================] - 0s 90us/sample - loss: 30.9179 - accuracy: 0.5422\n",
      "Epoch 16/100\n",
      "3259/3259 [==============================] - 0s 88us/sample - loss: 59.6474 - accuracy: 0.5379\n",
      "Epoch 17/100\n",
      "3259/3259 [==============================] - 0s 86us/sample - loss: 30.2479 - accuracy: 0.5232\n",
      "Epoch 18/100\n",
      "3259/3259 [==============================] - 0s 90us/sample - loss: 26.2070 - accuracy: 0.5462\n",
      "Epoch 19/100\n",
      "3259/3259 [==============================] - 0s 91us/sample - loss: 36.9131 - accuracy: 0.5373\n",
      "Epoch 20/100\n",
      "3259/3259 [==============================] - 0s 93us/sample - loss: 42.8715 - accuracy: 0.5173\n",
      "Epoch 21/100\n",
      "3259/3259 [==============================] - 0s 103us/sample - loss: 39.2194 - accuracy: 0.5315\n",
      "Epoch 22/100\n",
      "3259/3259 [==============================] - 0s 97us/sample - loss: 26.4377 - accuracy: 0.5222\n",
      "Epoch 23/100\n",
      "3259/3259 [==============================] - 0s 102us/sample - loss: 32.5847 - accuracy: 0.5210\n",
      "Epoch 24/100\n",
      "3259/3259 [==============================] - 0s 103us/sample - loss: 35.1949 - accuracy: 0.5186\n",
      "Epoch 25/100\n",
      "3259/3259 [==============================] - 0s 93us/sample - loss: 44.2987 - accuracy: 0.5235\n",
      "Epoch 26/100\n",
      "3259/3259 [==============================] - 0s 92us/sample - loss: 32.8293 - accuracy: 0.5339\n",
      "Epoch 27/100\n",
      "3259/3259 [==============================] - 0s 89us/sample - loss: 26.9681 - accuracy: 0.5336\n",
      "Epoch 28/100\n",
      "3259/3259 [==============================] - 0s 88us/sample - loss: 32.8113 - accuracy: 0.5311\n",
      "Epoch 29/100\n",
      "3259/3259 [==============================] - 0s 89us/sample - loss: 41.9504 - accuracy: 0.5268\n",
      "Epoch 30/100\n",
      "3259/3259 [==============================] - 0s 90us/sample - loss: 19.7570 - accuracy: 0.5388\n",
      "Epoch 31/100\n",
      "3259/3259 [==============================] - 0s 86us/sample - loss: 25.5072 - accuracy: 0.5348\n",
      "Epoch 32/100\n",
      "3259/3259 [==============================] - 0s 97us/sample - loss: 28.1485 - accuracy: 0.5376\n",
      "Epoch 33/100\n",
      "3259/3259 [==============================] - 0s 95us/sample - loss: 46.7903 - accuracy: 0.5204\n",
      "Epoch 34/100\n",
      "3259/3259 [==============================] - 0s 93us/sample - loss: 25.9455 - accuracy: 0.5318\n",
      "Epoch 35/100\n",
      "3259/3259 [==============================] - 0s 92us/sample - loss: 30.3432 - accuracy: 0.5336\n",
      "Epoch 36/100\n",
      "3259/3259 [==============================] - 0s 94us/sample - loss: 30.0893 - accuracy: 0.5465\n",
      "Epoch 37/100\n",
      "3259/3259 [==============================] - 0s 86us/sample - loss: 24.6345 - accuracy: 0.5486\n",
      "Epoch 38/100\n",
      "3259/3259 [==============================] - 0s 94us/sample - loss: 31.3619 - accuracy: 0.5431\n",
      "Epoch 39/100\n",
      "3259/3259 [==============================] - 0s 95us/sample - loss: 21.3013 - accuracy: 0.5327\n",
      "Epoch 40/100\n",
      "3259/3259 [==============================] - 0s 94us/sample - loss: 20.5881 - accuracy: 0.5529\n",
      "Epoch 41/100\n",
      "3259/3259 [==============================] - 0s 104us/sample - loss: 21.1132 - accuracy: 0.5348\n",
      "Epoch 42/100\n",
      "3259/3259 [==============================] - 0s 103us/sample - loss: 26.2868 - accuracy: 0.5379\n",
      "Epoch 43/100\n",
      "3259/3259 [==============================] - 0s 90us/sample - loss: 26.0010 - accuracy: 0.5394\n",
      "Epoch 44/100\n",
      "3259/3259 [==============================] - 0s 96us/sample - loss: 35.1960 - accuracy: 0.5440\n",
      "Epoch 45/100\n",
      "3259/3259 [==============================] - 0s 90us/sample - loss: 40.3053 - accuracy: 0.5207\n",
      "Epoch 46/100\n",
      "3259/3259 [==============================] - 0s 90us/sample - loss: 27.6964 - accuracy: 0.5394\n",
      "Epoch 47/100\n",
      "3259/3259 [==============================] - 0s 92us/sample - loss: 38.3433 - accuracy: 0.5305\n",
      "Epoch 48/100\n",
      "3259/3259 [==============================] - 0s 92us/sample - loss: 26.8123 - accuracy: 0.5373\n",
      "Epoch 49/100\n",
      "3259/3259 [==============================] - 0s 91us/sample - loss: 32.8188 - accuracy: 0.5351\n",
      "Epoch 50/100\n",
      "3259/3259 [==============================] - 0s 90us/sample - loss: 30.5126 - accuracy: 0.5342\n",
      "Epoch 51/100\n",
      "3259/3259 [==============================] - 0s 90us/sample - loss: 33.9862 - accuracy: 0.5284\n",
      "Epoch 52/100\n",
      "3259/3259 [==============================] - 0s 86us/sample - loss: 23.3617 - accuracy: 0.5348\n",
      "Epoch 53/100\n",
      "3259/3259 [==============================] - 0s 84us/sample - loss: 18.2824 - accuracy: 0.5459\n",
      "Epoch 54/100\n",
      "3259/3259 [==============================] - 0s 91us/sample - loss: 33.5373 - accuracy: 0.5428\n",
      "Epoch 55/100\n",
      "3259/3259 [==============================] - 0s 94us/sample - loss: 32.6362 - accuracy: 0.5321\n",
      "Epoch 56/100\n",
      "3259/3259 [==============================] - 0s 90us/sample - loss: 33.7531 - accuracy: 0.5192\n",
      "Epoch 57/100\n",
      "3259/3259 [==============================] - 0s 102us/sample - loss: 25.4396 - accuracy: 0.5201\n",
      "Epoch 58/100\n",
      "3259/3259 [==============================] - 0s 94us/sample - loss: 19.7505 - accuracy: 0.5588\n",
      "Epoch 59/100\n",
      "3259/3259 [==============================] - 0s 99us/sample - loss: 30.1662 - accuracy: 0.5431\n",
      "Epoch 60/100\n",
      "3259/3259 [==============================] - 0s 103us/sample - loss: 32.7821 - accuracy: 0.5468\n",
      "Epoch 61/100\n",
      "3259/3259 [==============================] - 0s 92us/sample - loss: 28.2043 - accuracy: 0.5560\n",
      "Epoch 62/100\n",
      "3259/3259 [==============================] - 0s 93us/sample - loss: 27.0898 - accuracy: 0.5443\n",
      "Epoch 63/100\n",
      "3259/3259 [==============================] - 0s 93us/sample - loss: 18.0006 - accuracy: 0.5634\n",
      "Epoch 64/100\n",
      "3259/3259 [==============================] - 0s 88us/sample - loss: 24.0982 - accuracy: 0.5394\n",
      "Epoch 65/100\n",
      "3259/3259 [==============================] - 0s 91us/sample - loss: 17.2179 - accuracy: 0.5502\n",
      "Epoch 66/100\n",
      "3259/3259 [==============================] - 0s 95us/sample - loss: 28.1089 - accuracy: 0.5471\n",
      "Epoch 67/100\n",
      "3259/3259 [==============================] - 0s 90us/sample - loss: 36.9822 - accuracy: 0.5155\n",
      "Epoch 68/100\n",
      "3259/3259 [==============================] - 0s 90us/sample - loss: 27.5302 - accuracy: 0.5357\n",
      "Epoch 69/100\n",
      "3259/3259 [==============================] - 0s 92us/sample - loss: 22.5110 - accuracy: 0.5321\n",
      "Epoch 70/100\n",
      "3259/3259 [==============================] - 0s 92us/sample - loss: 25.4432 - accuracy: 0.5373\n",
      "Epoch 71/100\n",
      "3259/3259 [==============================] - 0s 93us/sample - loss: 37.7939 - accuracy: 0.5407\n",
      "Epoch 72/100\n",
      "3259/3259 [==============================] - 0s 87us/sample - loss: 37.7801 - accuracy: 0.5416\n",
      "Epoch 73/100\n",
      "3259/3259 [==============================] - 0s 89us/sample - loss: 35.1876 - accuracy: 0.5523\n",
      "Epoch 74/100\n",
      "3259/3259 [==============================] - 0s 86us/sample - loss: 15.2192 - accuracy: 0.5588\n",
      "Epoch 75/100\n",
      "3259/3259 [==============================] - 0s 95us/sample - loss: 24.6020 - accuracy: 0.5575\n",
      "Epoch 76/100\n",
      "3259/3259 [==============================] - 0s 89us/sample - loss: 30.0857 - accuracy: 0.5342\n",
      "Epoch 77/100\n",
      "3259/3259 [==============================] - 0s 95us/sample - loss: 19.7373 - accuracy: 0.5339\n",
      "Epoch 78/100\n",
      "3259/3259 [==============================] - 0s 102us/sample - loss: 26.4830 - accuracy: 0.5474\n",
      "Epoch 79/100\n",
      "3259/3259 [==============================] - 0s 97us/sample - loss: 23.4425 - accuracy: 0.5480\n",
      "Epoch 80/100\n",
      "3259/3259 [==============================] - 0s 91us/sample - loss: 24.6512 - accuracy: 0.5600\n",
      "Epoch 81/100\n",
      "3259/3259 [==============================] - 0s 91us/sample - loss: 24.5570 - accuracy: 0.5581\n",
      "Epoch 82/100\n",
      "3259/3259 [==============================] - 0s 88us/sample - loss: 19.9323 - accuracy: 0.5572\n",
      "Epoch 83/100\n",
      "3259/3259 [==============================] - 0s 89us/sample - loss: 14.4071 - accuracy: 0.5545\n",
      "Epoch 84/100\n",
      "3259/3259 [==============================] - 0s 90us/sample - loss: 21.1298 - accuracy: 0.5505\n",
      "Epoch 85/100\n",
      "3259/3259 [==============================] - 0s 88us/sample - loss: 20.6567 - accuracy: 0.5413\n",
      "Epoch 86/100\n",
      "3259/3259 [==============================] - 0s 90us/sample - loss: 24.8732 - accuracy: 0.5557\n",
      "Epoch 87/100\n",
      "3259/3259 [==============================] - 0s 90us/sample - loss: 20.2562 - accuracy: 0.5612\n",
      "Epoch 88/100\n",
      "3259/3259 [==============================] - 0s 89us/sample - loss: 25.3110 - accuracy: 0.5376\n",
      "Epoch 89/100\n",
      "3259/3259 [==============================] - 0s 89us/sample - loss: 21.7610 - accuracy: 0.5505\n",
      "Epoch 90/100\n",
      "3259/3259 [==============================] - 0s 90us/sample - loss: 22.3224 - accuracy: 0.5477\n",
      "Epoch 91/100\n",
      "3259/3259 [==============================] - 0s 89us/sample - loss: 17.6531 - accuracy: 0.5370\n",
      "Epoch 92/100\n",
      "3259/3259 [==============================] - 0s 91us/sample - loss: 29.5593 - accuracy: 0.5262\n",
      "Epoch 93/100\n",
      "3259/3259 [==============================] - 0s 97us/sample - loss: 22.5654 - accuracy: 0.5517\n",
      "Epoch 94/100\n",
      "3259/3259 [==============================] - 0s 94us/sample - loss: 17.8155 - accuracy: 0.5496\n",
      "Epoch 95/100\n",
      "3259/3259 [==============================] - 0s 92us/sample - loss: 28.8068 - accuracy: 0.5330\n",
      "Epoch 96/100\n",
      "3259/3259 [==============================] - 0s 102us/sample - loss: 29.5328 - accuracy: 0.5437\n",
      "Epoch 97/100\n",
      "3259/3259 [==============================] - 0s 99us/sample - loss: 19.7684 - accuracy: 0.5499\n",
      "Epoch 98/100\n",
      "3259/3259 [==============================] - 0s 91us/sample - loss: 31.3141 - accuracy: 0.5348\n",
      "Epoch 99/100\n",
      "3259/3259 [==============================] - 0s 90us/sample - loss: 23.2842 - accuracy: 0.5428\n",
      "Epoch 100/100\n",
      "3259/3259 [==============================] - 0s 84us/sample - loss: 25.0873 - accuracy: 0.5511\n",
      "815/815 [==============================] - 0s 354us/sample - loss: 14.7621 - accuracy: 0.5791\n",
      "[14.762119798718786, 0.5791411]\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.88      0.68       407\n",
      "           1       0.70      0.27      0.40       408\n",
      "\n",
      "    accuracy                           0.58       815\n",
      "   macro avg       0.63      0.58      0.54       815\n",
      "weighted avg       0.63      0.58      0.54       815\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_preds = ANN(x_train, y_train, x_test, y_test, 'binary_crossentropy', -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "compare to previous one here precisoin,recall,f1-score are incressed for1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Method-2----->oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_class_0,count_class_1=df['Exited'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2_class_0=df1[df1['Exited']==0]\n",
    "df2_class_1=df1[df1['Exited']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7963, 11)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2_class_0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2037, 11)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2_class_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>7142</td>\n",
       "      <td>612</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>63</td>\n",
       "      <td>2</td>\n",
       "      <td>131629.17</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>122109.58</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7448</td>\n",
       "      <td>691</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>7</td>\n",
       "      <td>129934.64</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>75664.56</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8030</td>\n",
       "      <td>592</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>3</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12905.89</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2074</td>\n",
       "      <td>661</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "      <td>141136.62</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>189742.78</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7841</td>\n",
       "      <td>706</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>46</td>\n",
       "      <td>7</td>\n",
       "      <td>111288.18</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>149170.25</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1807</td>\n",
       "      <td>818</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>49</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>192298.84</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2135</td>\n",
       "      <td>736</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>57</td>\n",
       "      <td>9</td>\n",
       "      <td>95295.39</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>28434.44</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2787</td>\n",
       "      <td>805</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>6</td>\n",
       "      <td>118022.06</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>162643.15</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3998</td>\n",
       "      <td>639</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>5</td>\n",
       "      <td>162039.78</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>84361.72</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3560</td>\n",
       "      <td>817</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>8</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>65501.91</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7963 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      CreditScore  Geography  Gender  Age  Tenure    Balance  NumOfProducts  \\\n",
       "7142          612          2       1   63       2  131629.17              2   \n",
       "7448          691          2       0   36       7  129934.64              1   \n",
       "8030          592          2       0   38       3       0.00              1   \n",
       "2074          661          3       0   44       1  141136.62              1   \n",
       "7841          706          3       1   46       7  111288.18              1   \n",
       "...           ...        ...     ...  ...     ...        ...            ...   \n",
       "1807          818          1       1   49       2       0.00              1   \n",
       "2135          736          3       0   57       9   95295.39              1   \n",
       "2787          805          1       0   46       6  118022.06              3   \n",
       "3998          639          1       1   60       5  162039.78              1   \n",
       "3560          817          1       0   44       8       0.00              1   \n",
       "\n",
       "      HasCrCard  IsActiveMember  EstimatedSalary  Exited  \n",
       "7142          1               0        122109.58       1  \n",
       "7448          0               0         75664.56       1  \n",
       "8030          1               1         12905.89       1  \n",
       "2074          1               0        189742.78       1  \n",
       "7841          1               1        149170.25       1  \n",
       "...         ...             ...              ...     ...  \n",
       "1807          0               1        192298.84       1  \n",
       "2135          1               0         28434.44       1  \n",
       "2787          1               0        162643.15       1  \n",
       "3998          1               1         84361.72       1  \n",
       "3560          0               0         65501.91       1  \n",
       "\n",
       "[7963 rows x 11 columns]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2_class_1.sample(7963,replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7963, 11)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2_class_0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7963"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2_class_0.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>5350</td>\n",
       "      <td>477</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>57</td>\n",
       "      <td>9</td>\n",
       "      <td>114023.64</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>71167.17</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7487</td>\n",
       "      <td>651</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>56</td>\n",
       "      <td>4</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>84383.22</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5857</td>\n",
       "      <td>594</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>56</td>\n",
       "      <td>7</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>26215.85</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7181</td>\n",
       "      <td>736</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>7</td>\n",
       "      <td>117280.23</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>41921.06</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5514</td>\n",
       "      <td>641</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>65</td>\n",
       "      <td>6</td>\n",
       "      <td>38340.02</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>32607.77</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9856</td>\n",
       "      <td>763</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>108465.65</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>60552.44</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4889</td>\n",
       "      <td>691</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>41</td>\n",
       "      <td>8</td>\n",
       "      <td>109153.96</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>148848.76</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4471</td>\n",
       "      <td>826</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>56</td>\n",
       "      <td>8</td>\n",
       "      <td>174506.10</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>161802.82</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5033</td>\n",
       "      <td>536</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>61</td>\n",
       "      <td>8</td>\n",
       "      <td>65190.29</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>64308.49</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>109</td>\n",
       "      <td>479</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>9</td>\n",
       "      <td>92833.89</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>99449.86</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7963 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      CreditScore  Geography  Gender  Age  Tenure    Balance  NumOfProducts  \\\n",
       "5350          477          1       1   57       9  114023.64              2   \n",
       "7487          651          1       1   56       4       0.00              1   \n",
       "5857          594          1       1   56       7       0.00              1   \n",
       "7181          736          1       1   42       7  117280.23              3   \n",
       "5514          641          1       0   65       6   38340.02              1   \n",
       "...           ...        ...     ...  ...     ...        ...            ...   \n",
       "9856          763          3       1   32       1  108465.65              2   \n",
       "4889          691          3       1   41       8  109153.96              3   \n",
       "4471          826          2       1   56       8  174506.10              2   \n",
       "5033          536          1       1   61       8   65190.29              1   \n",
       "109           479          3       0   35       9   92833.89              1   \n",
       "\n",
       "      HasCrCard  IsActiveMember  EstimatedSalary  Exited  \n",
       "5350          1               1         71167.17       1  \n",
       "7487          0               0         84383.22       1  \n",
       "5857          1               0         26215.85       1  \n",
       "7181          0               0         41921.06       1  \n",
       "5514          1               0         32607.77       1  \n",
       "...         ...             ...              ...     ...  \n",
       "9856          1               0         60552.44       1  \n",
       "4889          1               1        148848.76       1  \n",
       "4471          0               1        161802.82       1  \n",
       "5033          1               1         64308.49       1  \n",
       "109           1               0         99449.86       1  \n",
       "\n",
       "[7963 rows x 11 columns]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2_class_1.sample(df2_class_0.shape[0],replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2_class_1_over=df2_class_1.sample(df2_class_0.shape[0],replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7963, 11), (7963, 11))"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2_class_1_over.shape,df2_class_0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15926, 11)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_over=pd.concat([df2_class_1_over,df2_class_0],axis=0)\n",
    "df_test_over.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random_over_sampling\n",
      "1    7963\n",
      "0    7963\n",
      "Name: Exited, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print('Random_over_sampling')\n",
    "print(df_test_over.Exited.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=df_test_over.drop('Exited',axis='columns')\n",
    "y=df_test_over['Exited']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=5,stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    6370\n",
       "0    6370\n",
       "Name: Exited, dtype: int64"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    1593\n",
       "0    1593\n",
       "Name: Exited, dtype: int64"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 12740 samples\n",
      "Epoch 1/100\n",
      "12740/12740 [==============================] - 2s 192us/sample - loss: 375.4036 - accuracy: 0.4994\n",
      "Epoch 2/100\n",
      "12740/12740 [==============================] - 2s 139us/sample - loss: 52.6864 - accuracy: 0.5013\n",
      "Epoch 3/100\n",
      "12740/12740 [==============================] - 2s 165us/sample - loss: 41.7590 - accuracy: 0.5155\n",
      "Epoch 4/100\n",
      "12740/12740 [==============================] - 2s 193us/sample - loss: 36.2468 - accuracy: 0.5070\n",
      "Epoch 5/100\n",
      "12740/12740 [==============================] - 2s 143us/sample - loss: 40.9648 - accuracy: 0.5124\n",
      "Epoch 6/100\n",
      "12740/12740 [==============================] - 2s 160us/sample - loss: 33.0190 - accuracy: 0.5173\n",
      "Epoch 7/100\n",
      "12740/12740 [==============================] - 2s 161us/sample - loss: 32.6521 - accuracy: 0.5173\n",
      "Epoch 8/100\n",
      "12740/12740 [==============================] - 2s 154us/sample - loss: 35.5470 - accuracy: 0.5210\n",
      "Epoch 9/100\n",
      "12740/12740 [==============================] - 2s 175us/sample - loss: 29.9798 - accuracy: 0.5199\n",
      "Epoch 10/100\n",
      "12740/12740 [==============================] - 2s 159us/sample - loss: 32.0162 - accuracy: 0.5271\n",
      "Epoch 11/100\n",
      "12740/12740 [==============================] - 2s 151us/sample - loss: 30.5088 - accuracy: 0.5197\n",
      "Epoch 12/100\n",
      "12740/12740 [==============================] - 2s 166us/sample - loss: 28.7036 - accuracy: 0.5318\n",
      "Epoch 13/100\n",
      "12740/12740 [==============================] - 2s 150us/sample - loss: 32.7188 - accuracy: 0.5209\n",
      "Epoch 14/100\n",
      "12740/12740 [==============================] - 2s 174us/sample - loss: 31.2533 - accuracy: 0.5254\n",
      "Epoch 15/100\n",
      "12740/12740 [==============================] - 2s 181us/sample - loss: 27.3934 - accuracy: 0.5249\n",
      "Epoch 16/100\n",
      "12740/12740 [==============================] - 2s 150us/sample - loss: 31.3888 - accuracy: 0.5230\n",
      "Epoch 17/100\n",
      "12740/12740 [==============================] - 2s 180us/sample - loss: 33.1531 - accuracy: 0.5251\n",
      "Epoch 18/100\n",
      "12740/12740 [==============================] - 2s 162us/sample - loss: 27.3626 - accuracy: 0.5258\n",
      "Epoch 19/100\n",
      "12740/12740 [==============================] - 2s 149us/sample - loss: 24.1447 - accuracy: 0.5367\n",
      "Epoch 20/100\n",
      "12740/12740 [==============================] - 2s 178us/sample - loss: 25.4943 - accuracy: 0.5333\n",
      "Epoch 21/100\n",
      "12740/12740 [==============================] - 2s 153us/sample - loss: 33.6674 - accuracy: 0.5330\n",
      "Epoch 22/100\n",
      "12740/12740 [==============================] - 2s 149us/sample - loss: 28.5912 - accuracy: 0.5411\n",
      "Epoch 23/100\n",
      "12740/12740 [==============================] - 2s 177us/sample - loss: 29.8367 - accuracy: 0.5306\n",
      "Epoch 24/100\n",
      "12740/12740 [==============================] - 2s 156us/sample - loss: 30.5710 - accuracy: 0.5309\n",
      "Epoch 25/100\n",
      "12740/12740 [==============================] - 2s 170us/sample - loss: 30.3779 - accuracy: 0.5319\n",
      "Epoch 26/100\n",
      "12740/12740 [==============================] - 1s 105us/sample - loss: 29.9733 - accuracy: 0.5319\n",
      "Epoch 27/100\n",
      "12740/12740 [==============================] - 2s 122us/sample - loss: 22.6299 - accuracy: 0.5378\n",
      "Epoch 28/100\n",
      "12740/12740 [==============================] - 2s 182us/sample - loss: 25.5207 - accuracy: 0.5312\n",
      "Epoch 29/100\n",
      "12740/12740 [==============================] - 2s 187us/sample - loss: 28.7070 - accuracy: 0.5376\n",
      "Epoch 30/100\n",
      "12740/12740 [==============================] - 2s 149us/sample - loss: 24.4030 - accuracy: 0.5390\n",
      "Epoch 31/100\n",
      "12740/12740 [==============================] - 2s 186us/sample - loss: 23.0655 - accuracy: 0.5431\n",
      "Epoch 32/100\n",
      "12740/12740 [==============================] - 2s 154us/sample - loss: 27.5848 - accuracy: 0.5296\n",
      "Epoch 33/100\n",
      "12740/12740 [==============================] - 2s 181us/sample - loss: 25.7015 - accuracy: 0.5375\n",
      "Epoch 34/100\n",
      "12740/12740 [==============================] - 2s 182us/sample - loss: 25.5158 - accuracy: 0.5377\n",
      "Epoch 35/100\n",
      "12740/12740 [==============================] - 2s 154us/sample - loss: 23.6231 - accuracy: 0.5339\n",
      "Epoch 36/100\n",
      "12740/12740 [==============================] - 2s 183us/sample - loss: 23.2845 - accuracy: 0.5400\n",
      "Epoch 37/100\n",
      "12740/12740 [==============================] - 2s 167us/sample - loss: 24.3213 - accuracy: 0.5464\n",
      "Epoch 38/100\n",
      "12740/12740 [==============================] - 2s 174us/sample - loss: 21.8439 - accuracy: 0.5374\n",
      "Epoch 39/100\n",
      "12740/12740 [==============================] - 2s 186us/sample - loss: 21.1188 - accuracy: 0.5399\n",
      "Epoch 40/100\n",
      "12740/12740 [==============================] - 2s 167us/sample - loss: 17.6450 - accuracy: 0.5516\n",
      "Epoch 41/100\n",
      "12740/12740 [==============================] - 2s 167us/sample - loss: 26.0014 - accuracy: 0.5385\n",
      "Epoch 42/100\n",
      "12740/12740 [==============================] - 2s 158us/sample - loss: 20.1285 - accuracy: 0.5463\n",
      "Epoch 43/100\n",
      "12740/12740 [==============================] - 2s 142us/sample - loss: 21.8482 - accuracy: 0.5462\n",
      "Epoch 44/100\n",
      "12740/12740 [==============================] - 2s 132us/sample - loss: 21.3882 - accuracy: 0.5513\n",
      "Epoch 45/100\n",
      "12740/12740 [==============================] - 2s 154us/sample - loss: 22.5525 - accuracy: 0.5402\n",
      "Epoch 46/100\n",
      "12740/12740 [==============================] - 2s 119us/sample - loss: 21.7192 - accuracy: 0.5511\n",
      "Epoch 47/100\n",
      "12740/12740 [==============================] - 2s 149us/sample - loss: 19.4651 - accuracy: 0.5503\n",
      "Epoch 48/100\n",
      "12740/12740 [==============================] - 2s 181us/sample - loss: 20.5433 - accuracy: 0.5527\n",
      "Epoch 49/100\n",
      "12740/12740 [==============================] - 2s 151us/sample - loss: 18.3659 - accuracy: 0.5538\n",
      "Epoch 50/100\n",
      "12740/12740 [==============================] - 2s 161us/sample - loss: 18.2301 - accuracy: 0.5511\n",
      "Epoch 51/100\n",
      "12740/12740 [==============================] - 2s 151us/sample - loss: 21.1170 - accuracy: 0.5361\n",
      "Epoch 52/100\n",
      "12740/12740 [==============================] - 2s 176us/sample - loss: 18.5000 - accuracy: 0.5531\n",
      "Epoch 53/100\n",
      "12740/12740 [==============================] - 2s 157us/sample - loss: 23.5336 - accuracy: 0.5425\n",
      "Epoch 54/100\n",
      "12740/12740 [==============================] - 2s 138us/sample - loss: 19.6703 - accuracy: 0.5532\n",
      "Epoch 55/100\n",
      "12740/12740 [==============================] - 2s 174us/sample - loss: 17.8199 - accuracy: 0.5582\n",
      "Epoch 56/100\n",
      "12740/12740 [==============================] - 2s 181us/sample - loss: 21.7060 - accuracy: 0.5464\n",
      "Epoch 57/100\n",
      "12740/12740 [==============================] - 2s 144us/sample - loss: 21.2795 - accuracy: 0.5535\n",
      "Epoch 58/100\n",
      "12740/12740 [==============================] - 2s 170us/sample - loss: 20.7727 - accuracy: 0.5430\n",
      "Epoch 59/100\n",
      "12740/12740 [==============================] - 2s 171us/sample - loss: 16.7562 - accuracy: 0.5564\n",
      "Epoch 60/100\n",
      "12740/12740 [==============================] - 2s 158us/sample - loss: 17.9738 - accuracy: 0.5500\n",
      "Epoch 61/100\n",
      "12740/12740 [==============================] - 2s 181us/sample - loss: 23.4128 - accuracy: 0.5486\n",
      "Epoch 62/100\n",
      "12740/12740 [==============================] - 2s 142us/sample - loss: 18.9313 - accuracy: 0.5522\n",
      "Epoch 63/100\n",
      "12740/12740 [==============================] - 2s 137us/sample - loss: 16.7315 - accuracy: 0.5535\n",
      "Epoch 64/100\n",
      "12740/12740 [==============================] - 2s 184us/sample - loss: 16.4136 - accuracy: 0.5597\n",
      "Epoch 65/100\n",
      "12740/12740 [==============================] - 2s 161us/sample - loss: 21.2613 - accuracy: 0.5407\n",
      "Epoch 66/100\n",
      "12740/12740 [==============================] - 2s 187us/sample - loss: 16.8962 - accuracy: 0.5497\n",
      "Epoch 67/100\n",
      "12740/12740 [==============================] - 2s 163us/sample - loss: 17.1309 - accuracy: 0.5495\n",
      "Epoch 68/100\n",
      "12740/12740 [==============================] - 2s 155us/sample - loss: 14.7903 - accuracy: 0.5539\n",
      "Epoch 69/100\n",
      "12740/12740 [==============================] - 2s 152us/sample - loss: 18.1546 - accuracy: 0.5509\n",
      "Epoch 70/100\n",
      "12740/12740 [==============================] - 2s 131us/sample - loss: 16.6602 - accuracy: 0.5579\n",
      "Epoch 71/100\n",
      "12740/12740 [==============================] - 2s 140us/sample - loss: 15.8009 - accuracy: 0.5589\n",
      "Epoch 72/100\n",
      "12740/12740 [==============================] - 2s 179us/sample - loss: 15.6174 - accuracy: 0.5626\n",
      "Epoch 73/100\n",
      "12740/12740 [==============================] - 2s 156us/sample - loss: 18.1201 - accuracy: 0.5525\n",
      "Epoch 74/100\n",
      "12740/12740 [==============================] - 2s 176us/sample - loss: 16.7239 - accuracy: 0.5500\n",
      "Epoch 75/100\n",
      "12740/12740 [==============================] - 2s 153us/sample - loss: 16.8979 - accuracy: 0.5604\n",
      "Epoch 76/100\n",
      "12740/12740 [==============================] - 2s 140us/sample - loss: 15.8768 - accuracy: 0.5590\n",
      "Epoch 77/100\n",
      "12740/12740 [==============================] - 2s 138us/sample - loss: 14.6709 - accuracy: 0.5535\n",
      "Epoch 78/100\n",
      "12740/12740 [==============================] - 2s 165us/sample - loss: 12.8716 - accuracy: 0.5695\n",
      "Epoch 79/100\n",
      "12740/12740 [==============================] - 2s 154us/sample - loss: 17.8272 - accuracy: 0.5533\n",
      "Epoch 80/100\n",
      "12740/12740 [==============================] - 2s 134us/sample - loss: 19.1389 - accuracy: 0.5509\n",
      "Epoch 81/100\n",
      "12740/12740 [==============================] - 2s 134us/sample - loss: 16.2667 - accuracy: 0.5488\n",
      "Epoch 82/100\n",
      "12740/12740 [==============================] - 2s 142us/sample - loss: 14.8006 - accuracy: 0.5564\n",
      "Epoch 83/100\n",
      "12740/12740 [==============================] - 2s 179us/sample - loss: 17.1374 - accuracy: 0.5518\n",
      "Epoch 84/100\n",
      "12740/12740 [==============================] - 2s 162us/sample - loss: 15.3437 - accuracy: 0.5612\n",
      "Epoch 85/100\n",
      "12740/12740 [==============================] - 2s 136us/sample - loss: 12.8744 - accuracy: 0.5647\n",
      "Epoch 86/100\n",
      "12740/12740 [==============================] - 2s 159us/sample - loss: 14.4506 - accuracy: 0.5627\n",
      "Epoch 87/100\n",
      "12740/12740 [==============================] - 2s 157us/sample - loss: 14.0688 - accuracy: 0.5593\n",
      "Epoch 88/100\n",
      "12740/12740 [==============================] - 2s 146us/sample - loss: 14.7714 - accuracy: 0.5482\n",
      "Epoch 89/100\n",
      "12740/12740 [==============================] - 2s 191us/sample - loss: 16.5979 - accuracy: 0.5641\n",
      "Epoch 90/100\n",
      "12740/12740 [==============================] - 2s 161us/sample - loss: 14.3522 - accuracy: 0.5535\n",
      "Epoch 91/100\n",
      "12740/12740 [==============================] - 2s 162us/sample - loss: 15.7567 - accuracy: 0.5587\n",
      "Epoch 92/100\n",
      "12740/12740 [==============================] - 2s 139us/sample - loss: 15.1043 - accuracy: 0.5568\n",
      "Epoch 93/100\n",
      "12740/12740 [==============================] - 2s 145us/sample - loss: 13.4889 - accuracy: 0.5638\n",
      "Epoch 94/100\n",
      "12740/12740 [==============================] - 2s 170us/sample - loss: 16.1154 - accuracy: 0.5513\n",
      "Epoch 95/100\n",
      "12740/12740 [==============================] - 2s 164us/sample - loss: 12.7665 - accuracy: 0.5589\n",
      "Epoch 96/100\n",
      "12740/12740 [==============================] - 1s 114us/sample - loss: 12.8498 - accuracy: 0.5547\n",
      "Epoch 97/100\n",
      "12740/12740 [==============================] - 2s 124us/sample - loss: 12.6451 - accuracy: 0.5610\n",
      "Epoch 98/100\n",
      "12740/12740 [==============================] - 1s 89us/sample - loss: 12.7420 - accuracy: 0.5693\n",
      "Epoch 99/100\n",
      "12740/12740 [==============================] - 1s 88us/sample - loss: 11.8236 - accuracy: 0.5651\n",
      "Epoch 100/100\n",
      "12740/12740 [==============================] - 1s 100us/sample - loss: 17.2865 - accuracy: 0.5510\n",
      "3186/3186 [==============================] - 1s 188us/sample - loss: 22.8501 - accuracy: 0.5035\n",
      "[22.85007055106585, 0.5034526]\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.98      0.66      1593\n",
      "           1       0.58      0.02      0.05      1593\n",
      "\n",
      "    accuracy                           0.50      3186\n",
      "   macro avg       0.54      0.50      0.36      3186\n",
      "weighted avg       0.54      0.50      0.36      3186\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_preds = ANN(x_train, y_train, x_test, y_test, 'binary_crossentropy', -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Method-3--------->SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=df1.drop('Exited',axis='columns')\n",
    "y=df1['Exited']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    7963\n",
       "1    2037\n",
       "Name: Exited, dtype: int64"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "smote=SMOTE(sampling_strategy='minority')\n",
    "x_s,y_s=smote.fit_sample(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((15926, 10), (15926,))"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_s.shape,y_s.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    7963\n",
       "0    7963\n",
       "Name: Exited, dtype: int64"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_s.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test=train_test_split(x_s,y_s,test_size=0.2,random_state=5,stratify=y_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    6370\n",
       "0    6370\n",
       "Name: Exited, dtype: int64"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    1593\n",
       "0    1593\n",
       "Name: Exited, dtype: int64"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 12740 samples\n",
      "Epoch 1/100\n",
      "12740/12740 [==============================] - 2s 194us/sample - loss: 589.4746 - accuracy: 0.5040\n",
      "Epoch 2/100\n",
      "12740/12740 [==============================] - 2s 174us/sample - loss: 53.3933 - accuracy: 0.5077\n",
      "Epoch 3/100\n",
      "12740/12740 [==============================] - 2s 163us/sample - loss: 54.9683 - accuracy: 0.5145\n",
      "Epoch 4/100\n",
      "12740/12740 [==============================] - 2s 172us/sample - loss: 42.2214 - accuracy: 0.5089\n",
      "Epoch 5/100\n",
      "12740/12740 [==============================] - 2s 144us/sample - loss: 44.4379 - accuracy: 0.5178\n",
      "Epoch 6/100\n",
      "12740/12740 [==============================] - 2s 157us/sample - loss: 44.6809 - accuracy: 0.5176\n",
      "Epoch 7/100\n",
      "12740/12740 [==============================] - 2s 158us/sample - loss: 36.1449 - accuracy: 0.5170\n",
      "Epoch 8/100\n",
      "12740/12740 [==============================] - 2s 128us/sample - loss: 38.4391 - accuracy: 0.5230\n",
      "Epoch 9/100\n",
      "12740/12740 [==============================] - 2s 158us/sample - loss: 38.2781 - accuracy: 0.5243\n",
      "Epoch 10/100\n",
      "12740/12740 [==============================] - 2s 150us/sample - loss: 36.9888 - accuracy: 0.5232\n",
      "Epoch 11/100\n",
      "12740/12740 [==============================] - 2s 145us/sample - loss: 36.5134 - accuracy: 0.5231\n",
      "Epoch 12/100\n",
      "12740/12740 [==============================] - 2s 151us/sample - loss: 34.9980 - accuracy: 0.5261\n",
      "Epoch 13/100\n",
      "12740/12740 [==============================] - 2s 152us/sample - loss: 40.6913 - accuracy: 0.5305\n",
      "Epoch 14/100\n",
      "12740/12740 [==============================] - 2s 141us/sample - loss: 38.9304 - accuracy: 0.5287\n",
      "Epoch 15/100\n",
      "12740/12740 [==============================] - 2s 149us/sample - loss: 36.5408 - accuracy: 0.5275\n",
      "Epoch 16/100\n",
      "12740/12740 [==============================] - 2s 149us/sample - loss: 41.3550 - accuracy: 0.5266\n",
      "Epoch 17/100\n",
      "12740/12740 [==============================] - 2s 136us/sample - loss: 34.8701 - accuracy: 0.5222\n",
      "Epoch 18/100\n",
      "12740/12740 [==============================] - 2s 150us/sample - loss: 35.1370 - accuracy: 0.5251\n",
      "Epoch 19/100\n",
      "12740/12740 [==============================] - 2s 149us/sample - loss: 35.1263 - accuracy: 0.5323\n",
      "Epoch 20/100\n",
      "12740/12740 [==============================] - 2s 134us/sample - loss: 29.0560 - accuracy: 0.5401\n",
      "Epoch 21/100\n",
      "12740/12740 [==============================] - 2s 167us/sample - loss: 39.9189 - accuracy: 0.5385\n",
      "Epoch 22/100\n",
      "12740/12740 [==============================] - 2s 168us/sample - loss: 32.6235 - accuracy: 0.5323\n",
      "Epoch 23/100\n",
      "12740/12740 [==============================] - 2s 136us/sample - loss: 36.9996 - accuracy: 0.5392\n",
      "Epoch 24/100\n",
      "12740/12740 [==============================] - 2s 155us/sample - loss: 35.7248 - accuracy: 0.5440\n",
      "Epoch 25/100\n",
      "12740/12740 [==============================] - 2s 154us/sample - loss: 35.5458 - accuracy: 0.5362\n",
      "Epoch 26/100\n",
      "12740/12740 [==============================] - 2s 133us/sample - loss: 24.9936 - accuracy: 0.5388\n",
      "Epoch 27/100\n",
      "12740/12740 [==============================] - 2s 164us/sample - loss: 27.5052 - accuracy: 0.5502\n",
      "Epoch 28/100\n",
      "12740/12740 [==============================] - 2s 172us/sample - loss: 25.5753 - accuracy: 0.5414\n",
      "Epoch 29/100\n",
      "12740/12740 [==============================] - 2s 148us/sample - loss: 37.8210 - accuracy: 0.5369\n",
      "Epoch 30/100\n",
      "12740/12740 [==============================] - 2s 179us/sample - loss: 26.9181 - accuracy: 0.5508\n",
      "Epoch 31/100\n",
      "12740/12740 [==============================] - 2s 149us/sample - loss: 25.5775 - accuracy: 0.5505\n",
      "Epoch 32/100\n",
      "12740/12740 [==============================] - 2s 178us/sample - loss: 33.5855 - accuracy: 0.5425\n",
      "Epoch 33/100\n",
      "12740/12740 [==============================] - 2s 181us/sample - loss: 34.8912 - accuracy: 0.5370\n",
      "Epoch 34/100\n",
      "12740/12740 [==============================] - ETA: 0s - loss: 41.5126 - accuracy: 0.533 - 2s 153us/sample - loss: 41.4321 - accuracy: 0.5336\n",
      "Epoch 35/100\n",
      "12740/12740 [==============================] - 2s 174us/sample - loss: 25.8278 - accuracy: 0.5535\n",
      "Epoch 36/100\n",
      "12740/12740 [==============================] - 2s 173us/sample - loss: 21.6034 - accuracy: 0.5625\n",
      "Epoch 37/100\n",
      "12740/12740 [==============================] - 2s 160us/sample - loss: 26.6562 - accuracy: 0.5478\n",
      "Epoch 38/100\n",
      "12740/12740 [==============================] - 2s 183us/sample - loss: 26.6315 - accuracy: 0.5454\n",
      "Epoch 39/100\n",
      "12740/12740 [==============================] - 2s 149us/sample - loss: 31.0345 - accuracy: 0.5497\n",
      "Epoch 40/100\n",
      "12740/12740 [==============================] - 2s 169us/sample - loss: 21.8131 - accuracy: 0.5571\n",
      "Epoch 41/100\n",
      "12740/12740 [==============================] - 2s 182us/sample - loss: 27.8896 - accuracy: 0.5423\n",
      "Epoch 42/100\n",
      "12740/12740 [==============================] - 2s 150us/sample - loss: 23.7660 - accuracy: 0.5515\n",
      "Epoch 43/100\n",
      "12740/12740 [==============================] - 2s 185us/sample - loss: 19.3596 - accuracy: 0.5625\n",
      "Epoch 44/100\n",
      "12740/12740 [==============================] - 2s 151us/sample - loss: 19.7493 - accuracy: 0.5587\n",
      "Epoch 45/100\n",
      "12740/12740 [==============================] - 2s 137us/sample - loss: 17.0293 - accuracy: 0.5724\n",
      "Epoch 46/100\n",
      "12740/12740 [==============================] - 2s 186us/sample - loss: 26.2428 - accuracy: 0.5546\n",
      "Epoch 47/100\n",
      "12740/12740 [==============================] - 2s 156us/sample - loss: 21.1929 - accuracy: 0.5612\n",
      "Epoch 48/100\n",
      "12740/12740 [==============================] - 2s 181us/sample - loss: 19.7939 - accuracy: 0.5666\n",
      "Epoch 49/100\n",
      "12740/12740 [==============================] - 2s 183us/sample - loss: 25.2246 - accuracy: 0.5600\n",
      "Epoch 50/100\n",
      "12740/12740 [==============================] - 2s 149us/sample - loss: 17.2908 - accuracy: 0.5677\n",
      "Epoch 51/100\n",
      "12740/12740 [==============================] - 2s 181us/sample - loss: 25.9335 - accuracy: 0.5467\n",
      "Epoch 52/100\n",
      "12740/12740 [==============================] - 2s 155us/sample - loss: 19.0524 - accuracy: 0.5663\n",
      "Epoch 53/100\n",
      "12740/12740 [==============================] - 2s 173us/sample - loss: 23.7147 - accuracy: 0.5508\n",
      "Epoch 54/100\n",
      "12740/12740 [==============================] - 2s 178us/sample - loss: 19.7383 - accuracy: 0.5499\n",
      "Epoch 55/100\n",
      "12740/12740 [==============================] - 2s 156us/sample - loss: 17.7982 - accuracy: 0.5638\n",
      "Epoch 56/100\n",
      "12740/12740 [==============================] - 2s 176us/sample - loss: 21.4561 - accuracy: 0.5585\n",
      "Epoch 57/100\n",
      "12740/12740 [==============================] - 2s 170us/sample - loss: 20.5496 - accuracy: 0.5520\n",
      "Epoch 58/100\n",
      "12740/12740 [==============================] - 2s 160us/sample - loss: 17.7717 - accuracy: 0.5658\n",
      "Epoch 59/100\n",
      "12740/12740 [==============================] - 2s 173us/sample - loss: 18.2134 - accuracy: 0.5616\n",
      "Epoch 60/100\n",
      "12740/12740 [==============================] - 2s 146us/sample - loss: 21.4553 - accuracy: 0.5587\n",
      "Epoch 61/100\n",
      "12740/12740 [==============================] - 2s 177us/sample - loss: 17.5968 - accuracy: 0.5693\n",
      "Epoch 62/100\n",
      "12740/12740 [==============================] - 2s 169us/sample - loss: 20.2937 - accuracy: 0.5636\n",
      "Epoch 63/100\n",
      "12740/12740 [==============================] - 2s 143us/sample - loss: 16.6964 - accuracy: 0.5618\n",
      "Epoch 64/100\n",
      "12740/12740 [==============================] - 2s 182us/sample - loss: 15.6177 - accuracy: 0.5696\n",
      "Epoch 65/100\n",
      "12740/12740 [==============================] - 2s 161us/sample - loss: 15.8168 - accuracy: 0.5728\n",
      "Epoch 66/100\n",
      "12740/12740 [==============================] - 2s 163us/sample - loss: 19.8236 - accuracy: 0.5608\n",
      "Epoch 67/100\n",
      "12740/12740 [==============================] - 2s 177us/sample - loss: 16.0335 - accuracy: 0.5689\n",
      "Epoch 68/100\n",
      "12740/12740 [==============================] - 2s 149us/sample - loss: 15.2055 - accuracy: 0.5696\n",
      "Epoch 69/100\n",
      "12740/12740 [==============================] - 2s 174us/sample - loss: 18.8046 - accuracy: 0.5637\n",
      "Epoch 70/100\n",
      "12740/12740 [==============================] - 2s 177us/sample - loss: 17.2647 - accuracy: 0.5669\n",
      "Epoch 71/100\n",
      "12740/12740 [==============================] - 2s 150us/sample - loss: 17.3771 - accuracy: 0.5685\n",
      "Epoch 72/100\n",
      "12740/12740 [==============================] - 2s 174us/sample - loss: 13.4981 - accuracy: 0.5859\n",
      "Epoch 73/100\n",
      "12740/12740 [==============================] - 2s 158us/sample - loss: 13.5198 - accuracy: 0.5853\n",
      "Epoch 74/100\n",
      "12740/12740 [==============================] - 2s 154us/sample - loss: 14.4320 - accuracy: 0.5719\n",
      "Epoch 75/100\n",
      "12740/12740 [==============================] - 2s 148us/sample - loss: 15.7056 - accuracy: 0.5812\n",
      "Epoch 76/100\n",
      "12740/12740 [==============================] - 2s 138us/sample - loss: 20.9460 - accuracy: 0.5484\n",
      "Epoch 77/100\n",
      "12740/12740 [==============================] - 2s 150us/sample - loss: 15.4380 - accuracy: 0.5763\n",
      "Epoch 78/100\n",
      "12740/12740 [==============================] - 2s 145us/sample - loss: 16.5877 - accuracy: 0.5695\n",
      "Epoch 79/100\n",
      "12740/12740 [==============================] - 2s 143us/sample - loss: 13.2946 - accuracy: 0.5745\n",
      "Epoch 80/100\n",
      "12740/12740 [==============================] - 2s 152us/sample - loss: 12.4415 - accuracy: 0.5794\n",
      "Epoch 81/100\n",
      "12740/12740 [==============================] - 2s 163us/sample - loss: 11.7296 - accuracy: 0.5825\n",
      "Epoch 82/100\n",
      "12740/12740 [==============================] - 2s 145us/sample - loss: 18.0996 - accuracy: 0.5656\n",
      "Epoch 83/100\n",
      "12740/12740 [==============================] - 2s 179us/sample - loss: 11.6168 - accuracy: 0.5881\n",
      "Epoch 84/100\n",
      "12740/12740 [==============================] - 2s 182us/sample - loss: 12.3913 - accuracy: 0.5801\n",
      "Epoch 85/100\n",
      "12740/12740 [==============================] - 2s 156us/sample - loss: 14.6857 - accuracy: 0.5641\n",
      "Epoch 86/100\n",
      "12740/12740 [==============================] - ETA: 0s - loss: 13.1789 - accuracy: 0.575 - 2s 178us/sample - loss: 13.0564 - accuracy: 0.5772\n",
      "Epoch 87/100\n",
      "12740/12740 [==============================] - 2s 166us/sample - loss: 10.5228 - accuracy: 0.5805\n",
      "Epoch 88/100\n",
      "12740/12740 [==============================] - 2s 166us/sample - loss: 17.2594 - accuracy: 0.5644\n",
      "Epoch 89/100\n",
      "12740/12740 [==============================] - 2s 182us/sample - loss: 13.2338 - accuracy: 0.5870\n",
      "Epoch 90/100\n",
      "12740/12740 [==============================] - 2s 150us/sample - loss: 10.4052 - accuracy: 0.5898\n",
      "Epoch 91/100\n",
      "12740/12740 [==============================] - 2s 181us/sample - loss: 10.8929 - accuracy: 0.5717\n",
      "Epoch 92/100\n",
      "12740/12740 [==============================] - 2s 175us/sample - loss: 12.9925 - accuracy: 0.5804\n",
      "Epoch 93/100\n",
      "12740/12740 [==============================] - 2s 151us/sample - loss: 11.2914 - accuracy: 0.5859\n",
      "Epoch 94/100\n",
      "12740/12740 [==============================] - 2s 184us/sample - loss: 11.6668 - accuracy: 0.5881\n",
      "Epoch 95/100\n",
      "12740/12740 [==============================] - 2s 155us/sample - loss: 12.3204 - accuracy: 0.5892\n",
      "Epoch 96/100\n",
      "12740/12740 [==============================] - 2s 189us/sample - loss: 9.9594 - accuracy: 0.5916\n",
      "Epoch 97/100\n",
      "12740/12740 [==============================] - 2s 167us/sample - loss: 11.0898 - accuracy: 0.5850\n",
      "Epoch 98/100\n",
      "12740/12740 [==============================] - 2s 145us/sample - loss: 12.8919 - accuracy: 0.5800\n",
      "Epoch 99/100\n",
      "12740/12740 [==============================] - 2s 142us/sample - loss: 11.8354 - accuracy: 0.5849\n",
      "Epoch 100/100\n",
      "12740/12740 [==============================] - 2s 147us/sample - loss: 10.2866 - accuracy: 0.5946\n",
      "3186/3186 [==============================] - 0s 145us/sample - loss: 11.4468 - accuracy: 0.5534\n",
      "[11.446770501600746, 0.55335844]\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.94      0.68      1593\n",
      "           1       0.74      0.16      0.27      1593\n",
      "\n",
      "    accuracy                           0.55      3186\n",
      "   macro avg       0.64      0.55      0.47      3186\n",
      "weighted avg       0.64      0.55      0.47      3186\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_preds = ANN(x_train, y_train, x_test, y_test, 'binary_crossentropy', -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Method_4------>using ensemble with undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    7963\n",
       "1    2037\n",
       "Name: Exited, dtype: int64"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.Exited.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=df1.drop('Exited',axis='columns')\n",
    "y=df1['Exited']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=5,stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    6370\n",
       "1    1630\n",
       "Name: Exited, dtype: int64"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.9079754601226995"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "6370/1630"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3=x_train.copy()\n",
    "df3['Exited']=y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3_class_0=df3[df3['Exited']==0]\n",
    "df3_class_1=df3[df3['Exited']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6370, 11), (1630, 11))"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3_class_0.shape,df3_class_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1630, 11)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3_class_0[0:1630].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_batch(df_majority,df_minority,start,end):\n",
    "    df3_train1=pd.concat([df_majority[start:end],df_minority],axis=0)\n",
    "    df3_train1.shape\n",
    "    \n",
    "    x_train=df3_train1.drop('Exited',axis='columns')\n",
    "    y_train=df3_train1['Exited']\n",
    "    \n",
    "    return x_train,y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6370, 11), (1630, 11))"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3_class_0.shape,df3_class_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8000, 10), (8000,))"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape,y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3260 samples\n",
      "Epoch 1/100\n",
      "3260/3260 [==============================] - 1s 234us/sample - loss: 8553.7899 - accuracy: 0.4758\n",
      "Epoch 2/100\n",
      "3260/3260 [==============================] - 0s 41us/sample - loss: 187.9601 - accuracy: 0.5199\n",
      "Epoch 3/100\n",
      "3260/3260 [==============================] - 0s 42us/sample - loss: 158.1455 - accuracy: 0.5221\n",
      "Epoch 4/100\n",
      "3260/3260 [==============================] - 0s 45us/sample - loss: 119.8569 - accuracy: 0.5153\n",
      "Epoch 5/100\n",
      "3260/3260 [==============================] - 0s 43us/sample - loss: 112.8334 - accuracy: 0.5117\n",
      "Epoch 6/100\n",
      "3260/3260 [==============================] - 0s 44us/sample - loss: 78.3774 - accuracy: 0.5043\n",
      "Epoch 7/100\n",
      "3260/3260 [==============================] - 0s 40us/sample - loss: 64.2993 - accuracy: 0.5104\n",
      "Epoch 8/100\n",
      "3260/3260 [==============================] - 0s 43us/sample - loss: 78.8240 - accuracy: 0.5061\n",
      "Epoch 9/100\n",
      "3260/3260 [==============================] - 0s 43us/sample - loss: 60.9941 - accuracy: 0.5150\n",
      "Epoch 10/100\n",
      "3260/3260 [==============================] - 0s 43us/sample - loss: 55.8421 - accuracy: 0.5163\n",
      "Epoch 11/100\n",
      "3260/3260 [==============================] - 0s 43us/sample - loss: 56.8260 - accuracy: 0.5175\n",
      "Epoch 12/100\n",
      "3260/3260 [==============================] - 0s 43us/sample - loss: 37.7074 - accuracy: 0.5178\n",
      "Epoch 13/100\n",
      "3260/3260 [==============================] - 0s 42us/sample - loss: 45.2146 - accuracy: 0.5163\n",
      "Epoch 14/100\n",
      "3260/3260 [==============================] - 0s 41us/sample - loss: 35.6315 - accuracy: 0.5175\n",
      "Epoch 15/100\n",
      "3260/3260 [==============================] - 0s 47us/sample - loss: 50.8270 - accuracy: 0.5095\n",
      "Epoch 16/100\n",
      "3260/3260 [==============================] - 0s 46us/sample - loss: 36.9532 - accuracy: 0.5166\n",
      "Epoch 17/100\n",
      "3260/3260 [==============================] - 0s 48us/sample - loss: 47.5996 - accuracy: 0.5163\n",
      "Epoch 18/100\n",
      "3260/3260 [==============================] - 0s 46us/sample - loss: 57.8841 - accuracy: 0.5046\n",
      "Epoch 19/100\n",
      "3260/3260 [==============================] - 0s 42us/sample - loss: 43.7879 - accuracy: 0.5150\n",
      "Epoch 20/100\n",
      "3260/3260 [==============================] - 0s 50us/sample - loss: 30.9851 - accuracy: 0.5040\n",
      "Epoch 21/100\n",
      "3260/3260 [==============================] - 0s 55us/sample - loss: 44.9217 - accuracy: 0.5138\n",
      "Epoch 22/100\n",
      "3260/3260 [==============================] - 0s 44us/sample - loss: 37.3060 - accuracy: 0.5245\n",
      "Epoch 23/100\n",
      "3260/3260 [==============================] - 0s 43us/sample - loss: 42.1346 - accuracy: 0.5028\n",
      "Epoch 24/100\n",
      "3260/3260 [==============================] - 0s 45us/sample - loss: 32.2761 - accuracy: 0.5144\n",
      "Epoch 25/100\n",
      "3260/3260 [==============================] - 0s 43us/sample - loss: 33.9671 - accuracy: 0.5169\n",
      "Epoch 26/100\n",
      "3260/3260 [==============================] - 0s 49us/sample - loss: 43.3480 - accuracy: 0.51200s - loss: 48.4125 - accuracy: 0.51\n",
      "Epoch 27/100\n",
      "3260/3260 [==============================] - 0s 46us/sample - loss: 47.5259 - accuracy: 0.5061\n",
      "Epoch 28/100\n",
      "3260/3260 [==============================] - 0s 45us/sample - loss: 53.1268 - accuracy: 0.5169\n",
      "Epoch 29/100\n",
      "3260/3260 [==============================] - 0s 49us/sample - loss: 39.1151 - accuracy: 0.5113\n",
      "Epoch 30/100\n",
      "3260/3260 [==============================] - 0s 46us/sample - loss: 52.6816 - accuracy: 0.5123\n",
      "Epoch 31/100\n",
      "3260/3260 [==============================] - 0s 49us/sample - loss: 34.9491 - accuracy: 0.5221\n",
      "Epoch 32/100\n",
      "3260/3260 [==============================] - 0s 48us/sample - loss: 34.8472 - accuracy: 0.5209\n",
      "Epoch 33/100\n",
      "3260/3260 [==============================] - 0s 45us/sample - loss: 31.6807 - accuracy: 0.5129\n",
      "Epoch 34/100\n",
      "3260/3260 [==============================] - 0s 43us/sample - loss: 40.2036 - accuracy: 0.5104\n",
      "Epoch 35/100\n",
      "3260/3260 [==============================] - 0s 44us/sample - loss: 41.1846 - accuracy: 0.5018\n",
      "Epoch 36/100\n",
      "3260/3260 [==============================] - 0s 43us/sample - loss: 33.6895 - accuracy: 0.5126\n",
      "Epoch 37/100\n",
      "3260/3260 [==============================] - 0s 43us/sample - loss: 29.2126 - accuracy: 0.5181\n",
      "Epoch 38/100\n",
      "3260/3260 [==============================] - 0s 45us/sample - loss: 40.4647 - accuracy: 0.49390s - loss: 43.6624 - accuracy: 0.483\n",
      "Epoch 39/100\n",
      "3260/3260 [==============================] - 0s 44us/sample - loss: 39.5446 - accuracy: 0.5117\n",
      "Epoch 40/100\n",
      "3260/3260 [==============================] - 0s 42us/sample - loss: 40.1386 - accuracy: 0.5025\n",
      "Epoch 41/100\n",
      "3260/3260 [==============================] - 0s 43us/sample - loss: 33.3591 - accuracy: 0.5242\n",
      "Epoch 42/100\n",
      "3260/3260 [==============================] - 0s 45us/sample - loss: 47.2341 - accuracy: 0.5135\n",
      "Epoch 43/100\n",
      "3260/3260 [==============================] - 0s 42us/sample - loss: 43.5160 - accuracy: 0.5120\n",
      "Epoch 44/100\n",
      "3260/3260 [==============================] - 0s 43us/sample - loss: 42.4656 - accuracy: 0.5184\n",
      "Epoch 45/100\n",
      "3260/3260 [==============================] - 0s 44us/sample - loss: 41.1137 - accuracy: 0.5298\n",
      "Epoch 46/100\n",
      "3260/3260 [==============================] - 0s 48us/sample - loss: 31.0493 - accuracy: 0.5224\n",
      "Epoch 47/100\n",
      "3260/3260 [==============================] - 0s 53us/sample - loss: 38.3814 - accuracy: 0.5282\n",
      "Epoch 48/100\n",
      "3260/3260 [==============================] - 0s 53us/sample - loss: 37.7428 - accuracy: 0.5067\n",
      "Epoch 49/100\n",
      "3260/3260 [==============================] - 0s 44us/sample - loss: 37.8034 - accuracy: 0.5187\n",
      "Epoch 50/100\n",
      "3260/3260 [==============================] - 0s 44us/sample - loss: 50.6979 - accuracy: 0.5135\n",
      "Epoch 51/100\n",
      "3260/3260 [==============================] - 0s 47us/sample - loss: 34.0719 - accuracy: 0.5181\n",
      "Epoch 52/100\n",
      "3260/3260 [==============================] - 0s 53us/sample - loss: 34.7850 - accuracy: 0.5181\n",
      "Epoch 53/100\n",
      "3260/3260 [==============================] - 0s 45us/sample - loss: 33.1152 - accuracy: 0.5270\n",
      "Epoch 54/100\n",
      "3260/3260 [==============================] - 0s 42us/sample - loss: 23.4369 - accuracy: 0.5098\n",
      "Epoch 55/100\n",
      "3260/3260 [==============================] - 0s 51us/sample - loss: 32.4675 - accuracy: 0.5120\n",
      "Epoch 56/100\n",
      "3260/3260 [==============================] - 0s 54us/sample - loss: 64.7149 - accuracy: 0.5181\n",
      "Epoch 57/100\n",
      "3260/3260 [==============================] - 0s 44us/sample - loss: 25.4130 - accuracy: 0.5285\n",
      "Epoch 58/100\n",
      "3260/3260 [==============================] - 0s 42us/sample - loss: 44.2526 - accuracy: 0.5169\n",
      "Epoch 59/100\n",
      "3260/3260 [==============================] - 0s 41us/sample - loss: 33.2379 - accuracy: 0.5255\n",
      "Epoch 60/100\n",
      "3260/3260 [==============================] - 0s 43us/sample - loss: 27.3347 - accuracy: 0.5466\n",
      "Epoch 61/100\n",
      "3260/3260 [==============================] - 0s 40us/sample - loss: 32.5733 - accuracy: 0.5003\n",
      "Epoch 62/100\n",
      "3260/3260 [==============================] - 0s 46us/sample - loss: 30.3887 - accuracy: 0.5160\n",
      "Epoch 63/100\n",
      "3260/3260 [==============================] - 0s 40us/sample - loss: 41.5643 - accuracy: 0.5199\n",
      "Epoch 64/100\n",
      "3260/3260 [==============================] - 0s 42us/sample - loss: 33.4314 - accuracy: 0.50890s - loss: 28.5925 - accuracy: 0.510\n",
      "Epoch 65/100\n",
      "3260/3260 [==============================] - 0s 42us/sample - loss: 39.6619 - accuracy: 0.5147\n",
      "Epoch 66/100\n",
      "3260/3260 [==============================] - 0s 42us/sample - loss: 30.7232 - accuracy: 0.5184\n",
      "Epoch 67/100\n",
      "3260/3260 [==============================] - 0s 41us/sample - loss: 36.7240 - accuracy: 0.5270\n",
      "Epoch 68/100\n",
      "3260/3260 [==============================] - 0s 41us/sample - loss: 22.3654 - accuracy: 0.5387\n",
      "Epoch 69/100\n",
      "3260/3260 [==============================] - 0s 44us/sample - loss: 45.3835 - accuracy: 0.5261\n",
      "Epoch 70/100\n",
      "3260/3260 [==============================] - 0s 42us/sample - loss: 34.7946 - accuracy: 0.5282\n",
      "Epoch 71/100\n",
      "3260/3260 [==============================] - 0s 42us/sample - loss: 26.0979 - accuracy: 0.5374\n",
      "Epoch 72/100\n",
      "3260/3260 [==============================] - 0s 43us/sample - loss: 42.4836 - accuracy: 0.5273\n",
      "Epoch 73/100\n",
      "3260/3260 [==============================] - 0s 45us/sample - loss: 39.5155 - accuracy: 0.5224\n",
      "Epoch 74/100\n",
      "3260/3260 [==============================] - 0s 41us/sample - loss: 35.5670 - accuracy: 0.5067\n",
      "Epoch 75/100\n",
      "3260/3260 [==============================] - 0s 43us/sample - loss: 40.8230 - accuracy: 0.5181\n",
      "Epoch 76/100\n",
      "3260/3260 [==============================] - 0s 39us/sample - loss: 33.2314 - accuracy: 0.5236\n",
      "Epoch 77/100\n",
      "3260/3260 [==============================] - 0s 42us/sample - loss: 28.7783 - accuracy: 0.5095\n",
      "Epoch 78/100\n",
      "3260/3260 [==============================] - 0s 40us/sample - loss: 32.1527 - accuracy: 0.5113\n",
      "Epoch 79/100\n",
      "3260/3260 [==============================] - 0s 40us/sample - loss: 27.7760 - accuracy: 0.5206\n",
      "Epoch 80/100\n",
      "3260/3260 [==============================] - 0s 41us/sample - loss: 41.5271 - accuracy: 0.5018\n",
      "Epoch 81/100\n",
      "3260/3260 [==============================] - 0s 41us/sample - loss: 38.4239 - accuracy: 0.5196\n",
      "Epoch 82/100\n",
      "3260/3260 [==============================] - 0s 39us/sample - loss: 35.4328 - accuracy: 0.5328\n",
      "Epoch 83/100\n",
      "3260/3260 [==============================] - 0s 41us/sample - loss: 30.6699 - accuracy: 0.5218\n",
      "Epoch 84/100\n",
      "3260/3260 [==============================] - 0s 43us/sample - loss: 39.1250 - accuracy: 0.5126\n",
      "Epoch 85/100\n",
      "3260/3260 [==============================] - 0s 39us/sample - loss: 31.1055 - accuracy: 0.5390\n",
      "Epoch 86/100\n",
      "3260/3260 [==============================] - 0s 39us/sample - loss: 43.2027 - accuracy: 0.5307\n",
      "Epoch 87/100\n",
      "3260/3260 [==============================] - 0s 39us/sample - loss: 35.1625 - accuracy: 0.5279\n",
      "Epoch 88/100\n",
      "3260/3260 [==============================] - 0s 40us/sample - loss: 31.1303 - accuracy: 0.5233\n",
      "Epoch 89/100\n",
      "3260/3260 [==============================] - 0s 46us/sample - loss: 25.0384 - accuracy: 0.5147\n",
      "Epoch 90/100\n",
      "3260/3260 [==============================] - 0s 43us/sample - loss: 32.5212 - accuracy: 0.5089\n",
      "Epoch 91/100\n",
      "3260/3260 [==============================] - 0s 39us/sample - loss: 46.8252 - accuracy: 0.5123\n",
      "Epoch 92/100\n",
      "3260/3260 [==============================] - 0s 41us/sample - loss: 33.0162 - accuracy: 0.5193\n",
      "Epoch 93/100\n",
      "3260/3260 [==============================] - 0s 44us/sample - loss: 31.8616 - accuracy: 0.5316\n",
      "Epoch 94/100\n",
      "3260/3260 [==============================] - 0s 54us/sample - loss: 24.4342 - accuracy: 0.5252\n",
      "Epoch 95/100\n",
      "3260/3260 [==============================] - 0s 40us/sample - loss: 28.0320 - accuracy: 0.5245\n",
      "Epoch 96/100\n",
      "3260/3260 [==============================] - 0s 39us/sample - loss: 25.3890 - accuracy: 0.5288\n",
      "Epoch 97/100\n",
      "3260/3260 [==============================] - 0s 38us/sample - loss: 37.5154 - accuracy: 0.5417\n",
      "Epoch 98/100\n",
      "3260/3260 [==============================] - 0s 41us/sample - loss: 31.6341 - accuracy: 0.5123\n",
      "Epoch 99/100\n",
      "3260/3260 [==============================] - 0s 39us/sample - loss: 22.5556 - accuracy: 0.5294\n",
      "Epoch 100/100\n",
      "3260/3260 [==============================] - 0s 41us/sample - loss: 30.7695 - accuracy: 0.5117\n",
      "2000/2000 [==============================] - 0s 73us/sample - loss: 31.1880 - accuracy: 0.2435\n",
      "[31.1879690246582, 0.2435]\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.07      0.13      1593\n",
      "           1       0.20      0.92      0.33       407\n",
      "\n",
      "    accuracy                           0.24      2000\n",
      "   macro avg       0.49      0.50      0.23      2000\n",
      "weighted avg       0.66      0.24      0.17      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x_train,y_train=get_train_batch(df3_class_0,df3_class_1,0,1630)\n",
    "y_preds_1 = ANN(x_train, y_train, x_test, y_test, 'binary_crossentropy', -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3260 samples\n",
      "Epoch 1/100\n",
      "3260/3260 [==============================] - 1s 180us/sample - loss: 17856.3057 - accuracy: 0.5000\n",
      "Epoch 2/100\n",
      "3260/3260 [==============================] - 0s 41us/sample - loss: 2348.1493 - accuracy: 0.5387\n",
      "Epoch 3/100\n",
      "3260/3260 [==============================] - 0s 44us/sample - loss: 209.0169 - accuracy: 0.5245\n",
      "Epoch 4/100\n",
      "3260/3260 [==============================] - 0s 41us/sample - loss: 129.8990 - accuracy: 0.5166\n",
      "Epoch 5/100\n",
      "3260/3260 [==============================] - 0s 42us/sample - loss: 107.0955 - accuracy: 0.5221\n",
      "Epoch 6/100\n",
      "3260/3260 [==============================] - 0s 42us/sample - loss: 89.1434 - accuracy: 0.5230\n",
      "Epoch 7/100\n",
      "3260/3260 [==============================] - 0s 43us/sample - loss: 80.2297 - accuracy: 0.51810s - loss: 77.7182 - accuracy: 0.53\n",
      "Epoch 8/100\n",
      "3260/3260 [==============================] - 0s 45us/sample - loss: 70.8372 - accuracy: 0.53400s - loss: 78.9370 - accuracy: 0.52\n",
      "Epoch 9/100\n",
      "3260/3260 [==============================] - 0s 45us/sample - loss: 58.2168 - accuracy: 0.5242\n",
      "Epoch 10/100\n",
      "3260/3260 [==============================] - 0s 42us/sample - loss: 51.0414 - accuracy: 0.5169\n",
      "Epoch 11/100\n",
      "3260/3260 [==============================] - 0s 42us/sample - loss: 48.3582 - accuracy: 0.5074\n",
      "Epoch 12/100\n",
      "3260/3260 [==============================] - 0s 43us/sample - loss: 35.3668 - accuracy: 0.5387\n",
      "Epoch 13/100\n",
      "3260/3260 [==============================] - 0s 41us/sample - loss: 28.8699 - accuracy: 0.5463\n",
      "Epoch 14/100\n",
      "3260/3260 [==============================] - 0s 45us/sample - loss: 36.5951 - accuracy: 0.5279\n",
      "Epoch 15/100\n",
      "3260/3260 [==============================] - 0s 42us/sample - loss: 36.9111 - accuracy: 0.5187\n",
      "Epoch 16/100\n",
      "3260/3260 [==============================] - 0s 44us/sample - loss: 26.1012 - accuracy: 0.5301\n",
      "Epoch 17/100\n",
      "3260/3260 [==============================] - 0s 44us/sample - loss: 24.6178 - accuracy: 0.5252\n",
      "Epoch 18/100\n",
      "3260/3260 [==============================] - 0s 43us/sample - loss: 27.4782 - accuracy: 0.5181\n",
      "Epoch 19/100\n",
      "3260/3260 [==============================] - 0s 44us/sample - loss: 31.3857 - accuracy: 0.5089\n",
      "Epoch 20/100\n",
      "3260/3260 [==============================] - 0s 44us/sample - loss: 23.6919 - accuracy: 0.5175\n",
      "Epoch 21/100\n",
      "3260/3260 [==============================] - 0s 46us/sample - loss: 20.5836 - accuracy: 0.5264\n",
      "Epoch 22/100\n",
      "3260/3260 [==============================] - 0s 51us/sample - loss: 32.8499 - accuracy: 0.5261\n",
      "Epoch 23/100\n",
      "3260/3260 [==============================] - 0s 46us/sample - loss: 25.9960 - accuracy: 0.5267\n",
      "Epoch 24/100\n",
      "3260/3260 [==============================] - 0s 47us/sample - loss: 17.8452 - accuracy: 0.5233\n",
      "Epoch 25/100\n",
      "3260/3260 [==============================] - 0s 48us/sample - loss: 18.3917 - accuracy: 0.5261\n",
      "Epoch 26/100\n",
      "3260/3260 [==============================] - 0s 67us/sample - loss: 20.3029 - accuracy: 0.4942\n",
      "Epoch 27/100\n",
      "3260/3260 [==============================] - 0s 57us/sample - loss: 25.3331 - accuracy: 0.5184\n",
      "Epoch 28/100\n",
      "3260/3260 [==============================] - 0s 42us/sample - loss: 22.9034 - accuracy: 0.5098\n",
      "Epoch 29/100\n",
      "3260/3260 [==============================] - 0s 43us/sample - loss: 20.2060 - accuracy: 0.5221\n",
      "Epoch 30/100\n",
      "3260/3260 [==============================] - 0s 44us/sample - loss: 13.8765 - accuracy: 0.5132\n",
      "Epoch 31/100\n",
      "3260/3260 [==============================] - 0s 44us/sample - loss: 20.7529 - accuracy: 0.5227\n",
      "Epoch 32/100\n",
      "3260/3260 [==============================] - 0s 42us/sample - loss: 28.8998 - accuracy: 0.5193\n",
      "Epoch 33/100\n",
      "3260/3260 [==============================] - 0s 43us/sample - loss: 25.5998 - accuracy: 0.5233\n",
      "Epoch 34/100\n",
      "3260/3260 [==============================] - 0s 42us/sample - loss: 23.0852 - accuracy: 0.5086\n",
      "Epoch 35/100\n",
      "3260/3260 [==============================] - 0s 41us/sample - loss: 17.8538 - accuracy: 0.5166\n",
      "Epoch 36/100\n",
      "3260/3260 [==============================] - 0s 43us/sample - loss: 23.9795 - accuracy: 0.5270\n",
      "Epoch 37/100\n",
      "3260/3260 [==============================] - 0s 42us/sample - loss: 21.1041 - accuracy: 0.5215\n",
      "Epoch 38/100\n",
      "3260/3260 [==============================] - 0s 41us/sample - loss: 13.3203 - accuracy: 0.5356\n",
      "Epoch 39/100\n",
      "3260/3260 [==============================] - 0s 44us/sample - loss: 13.8881 - accuracy: 0.5193\n",
      "Epoch 40/100\n",
      "3260/3260 [==============================] - 0s 42us/sample - loss: 15.8153 - accuracy: 0.5184\n",
      "Epoch 41/100\n",
      "3260/3260 [==============================] - 0s 46us/sample - loss: 19.3849 - accuracy: 0.52550s - loss: 18.6442 - accuracy: 0.51\n",
      "Epoch 42/100\n",
      "3260/3260 [==============================] - 0s 42us/sample - loss: 16.7123 - accuracy: 0.5242\n",
      "Epoch 43/100\n",
      "3260/3260 [==============================] - 0s 42us/sample - loss: 18.7156 - accuracy: 0.5101\n",
      "Epoch 44/100\n",
      "3260/3260 [==============================] - 0s 42us/sample - loss: 26.4807 - accuracy: 0.5043\n",
      "Epoch 45/100\n",
      "3260/3260 [==============================] - 0s 44us/sample - loss: 26.0885 - accuracy: 0.5255\n",
      "Epoch 46/100\n",
      "3260/3260 [==============================] - 0s 42us/sample - loss: 16.1890 - accuracy: 0.5322\n",
      "Epoch 47/100\n",
      "3260/3260 [==============================] - 0s 43us/sample - loss: 17.6909 - accuracy: 0.5071\n",
      "Epoch 48/100\n",
      "3260/3260 [==============================] - 0s 50us/sample - loss: 15.6498 - accuracy: 0.5190\n",
      "Epoch 49/100\n",
      "3260/3260 [==============================] - 0s 50us/sample - loss: 17.5991 - accuracy: 0.5107\n",
      "Epoch 50/100\n",
      "3260/3260 [==============================] - 0s 53us/sample - loss: 18.8745 - accuracy: 0.5347\n",
      "Epoch 51/100\n",
      "3260/3260 [==============================] - 0s 51us/sample - loss: 22.8052 - accuracy: 0.5209\n",
      "Epoch 52/100\n",
      "3260/3260 [==============================] - 0s 53us/sample - loss: 14.2983 - accuracy: 0.5236\n",
      "Epoch 53/100\n",
      "3260/3260 [==============================] - 0s 44us/sample - loss: 19.7393 - accuracy: 0.5325\n",
      "Epoch 54/100\n",
      "3260/3260 [==============================] - 0s 43us/sample - loss: 18.4576 - accuracy: 0.5460\n",
      "Epoch 55/100\n",
      "3260/3260 [==============================] - 0s 40us/sample - loss: 16.6549 - accuracy: 0.5242\n",
      "Epoch 56/100\n",
      "3260/3260 [==============================] - 0s 43us/sample - loss: 14.7985 - accuracy: 0.5150\n",
      "Epoch 57/100\n",
      "3260/3260 [==============================] - 0s 51us/sample - loss: 20.6067 - accuracy: 0.5077\n",
      "Epoch 58/100\n",
      "3260/3260 [==============================] - 0s 40us/sample - loss: 15.3012 - accuracy: 0.5396\n",
      "Epoch 59/100\n",
      "3260/3260 [==============================] - 0s 38us/sample - loss: 17.1292 - accuracy: 0.5239\n",
      "Epoch 60/100\n",
      "3260/3260 [==============================] - 0s 40us/sample - loss: 16.0203 - accuracy: 0.5242\n",
      "Epoch 61/100\n",
      "3260/3260 [==============================] - 0s 39us/sample - loss: 14.8510 - accuracy: 0.5307\n",
      "Epoch 62/100\n",
      "3260/3260 [==============================] - 0s 47us/sample - loss: 28.0672 - accuracy: 0.5209\n",
      "Epoch 63/100\n",
      "3260/3260 [==============================] - 0s 50us/sample - loss: 15.8541 - accuracy: 0.5310\n",
      "Epoch 64/100\n",
      "3260/3260 [==============================] - 0s 42us/sample - loss: 15.6215 - accuracy: 0.5190\n",
      "Epoch 65/100\n",
      "3260/3260 [==============================] - 0s 40us/sample - loss: 19.2252 - accuracy: 0.5190\n",
      "Epoch 66/100\n",
      "3260/3260 [==============================] - 0s 39us/sample - loss: 15.2707 - accuracy: 0.5288\n",
      "Epoch 67/100\n",
      "3260/3260 [==============================] - 0s 40us/sample - loss: 13.8664 - accuracy: 0.5380\n",
      "Epoch 68/100\n",
      "3260/3260 [==============================] - 0s 52us/sample - loss: 16.0585 - accuracy: 0.5261\n",
      "Epoch 69/100\n",
      "3260/3260 [==============================] - 0s 41us/sample - loss: 15.5122 - accuracy: 0.5178\n",
      "Epoch 70/100\n",
      "3260/3260 [==============================] - 0s 40us/sample - loss: 17.1175 - accuracy: 0.5350\n",
      "Epoch 71/100\n",
      "3260/3260 [==============================] - 0s 40us/sample - loss: 24.3468 - accuracy: 0.5242\n",
      "Epoch 72/100\n",
      "3260/3260 [==============================] - 0s 41us/sample - loss: 14.2881 - accuracy: 0.5365\n",
      "Epoch 73/100\n",
      "3260/3260 [==============================] - 0s 40us/sample - loss: 17.8528 - accuracy: 0.5236\n",
      "Epoch 74/100\n",
      "3260/3260 [==============================] - 0s 45us/sample - loss: 16.1391 - accuracy: 0.5285\n",
      "Epoch 75/100\n",
      "3260/3260 [==============================] - 0s 57us/sample - loss: 20.6052 - accuracy: 0.52360s - loss: 19.2393 - accuracy: 0.50\n",
      "Epoch 76/100\n",
      "3260/3260 [==============================] - 0s 41us/sample - loss: 20.5731 - accuracy: 0.5172\n",
      "Epoch 77/100\n",
      "3260/3260 [==============================] - 0s 40us/sample - loss: 18.0563 - accuracy: 0.5163\n",
      "Epoch 78/100\n",
      "3260/3260 [==============================] - 0s 42us/sample - loss: 13.7432 - accuracy: 0.5212\n",
      "Epoch 79/100\n",
      "3260/3260 [==============================] - 0s 40us/sample - loss: 14.7701 - accuracy: 0.5322\n",
      "Epoch 80/100\n",
      "3260/3260 [==============================] - 0s 39us/sample - loss: 19.4984 - accuracy: 0.5147\n",
      "Epoch 81/100\n",
      "3260/3260 [==============================] - 0s 39us/sample - loss: 14.7070 - accuracy: 0.5153\n",
      "Epoch 82/100\n",
      "3260/3260 [==============================] - 0s 42us/sample - loss: 16.4332 - accuracy: 0.5353\n",
      "Epoch 83/100\n",
      "3260/3260 [==============================] - 0s 41us/sample - loss: 12.8654 - accuracy: 0.5433\n",
      "Epoch 84/100\n",
      "3260/3260 [==============================] - 0s 40us/sample - loss: 12.7250 - accuracy: 0.5193\n",
      "Epoch 85/100\n",
      "3260/3260 [==============================] - 0s 40us/sample - loss: 21.6519 - accuracy: 0.5184\n",
      "Epoch 86/100\n",
      "3260/3260 [==============================] - 0s 41us/sample - loss: 9.7310 - accuracy: 0.5245\n",
      "Epoch 87/100\n",
      "3260/3260 [==============================] - 0s 40us/sample - loss: 17.9088 - accuracy: 0.5135\n",
      "Epoch 88/100\n",
      "3260/3260 [==============================] - 0s 40us/sample - loss: 12.8571 - accuracy: 0.5184\n",
      "Epoch 89/100\n",
      "3260/3260 [==============================] - 0s 39us/sample - loss: 13.8443 - accuracy: 0.5362\n",
      "Epoch 90/100\n",
      "3260/3260 [==============================] - 0s 43us/sample - loss: 12.5422 - accuracy: 0.5215\n",
      "Epoch 91/100\n",
      "3260/3260 [==============================] - 0s 40us/sample - loss: 15.7391 - accuracy: 0.5181\n",
      "Epoch 92/100\n",
      "3260/3260 [==============================] - 0s 39us/sample - loss: 10.8371 - accuracy: 0.5350\n",
      "Epoch 93/100\n",
      "3260/3260 [==============================] - 0s 39us/sample - loss: 11.4273 - accuracy: 0.5371\n",
      "Epoch 94/100\n",
      "3260/3260 [==============================] - 0s 42us/sample - loss: 17.8139 - accuracy: 0.5206\n",
      "Epoch 95/100\n",
      "3260/3260 [==============================] - 0s 50us/sample - loss: 17.4194 - accuracy: 0.5291\n",
      "Epoch 96/100\n",
      "3260/3260 [==============================] - 0s 41us/sample - loss: 11.1195 - accuracy: 0.5433\n",
      "Epoch 97/100\n",
      "3260/3260 [==============================] - 0s 39us/sample - loss: 10.9994 - accuracy: 0.5276\n",
      "Epoch 98/100\n",
      "3260/3260 [==============================] - 0s 39us/sample - loss: 10.4800 - accuracy: 0.5451\n",
      "Epoch 99/100\n",
      "3260/3260 [==============================] - 0s 40us/sample - loss: 15.4793 - accuracy: 0.5270\n",
      "Epoch 100/100\n",
      "3260/3260 [==============================] - 0s 45us/sample - loss: 16.9213 - accuracy: 0.5288\n",
      "2000/2000 [==============================] - 0s 94us/sample - loss: 16.7216 - accuracy: 0.2900\n",
      "[16.721599822998048, 0.29]\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.15      0.25      1593\n",
      "           1       0.20      0.86      0.33       407\n",
      "\n",
      "    accuracy                           0.29      2000\n",
      "   macro avg       0.50      0.50      0.29      2000\n",
      "weighted avg       0.68      0.29      0.26      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x_train,y_train=get_train_batch(df3_class_0,df3_class_1,1630,3260)\n",
    "y_preds_2 = ANN(x_train, y_train, x_test, y_test, 'binary_crossentropy', -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3260 samples\n",
      "Epoch 1/100\n",
      "3260/3260 [==============================] - 1s 197us/sample - loss: 3424.6170 - accuracy: 0.4595\n",
      "Epoch 2/100\n",
      "3260/3260 [==============================] - 0s 41us/sample - loss: 137.0098 - accuracy: 0.4868\n",
      "Epoch 3/100\n",
      "3260/3260 [==============================] - 0s 41us/sample - loss: 56.1561 - accuracy: 0.4954\n",
      "Epoch 4/100\n",
      "3260/3260 [==============================] - 0s 44us/sample - loss: 45.1372 - accuracy: 0.5117\n",
      "Epoch 5/100\n",
      "3260/3260 [==============================] - 0s 54us/sample - loss: 45.6520 - accuracy: 0.5135\n",
      "Epoch 6/100\n",
      "3260/3260 [==============================] - 0s 47us/sample - loss: 40.8272 - accuracy: 0.5178\n",
      "Epoch 7/100\n",
      "3260/3260 [==============================] - 0s 41us/sample - loss: 42.3637 - accuracy: 0.4936\n",
      "Epoch 8/100\n",
      "3260/3260 [==============================] - 0s 42us/sample - loss: 34.9939 - accuracy: 0.5077\n",
      "Epoch 9/100\n",
      "3260/3260 [==============================] - 0s 41us/sample - loss: 27.3862 - accuracy: 0.5365\n",
      "Epoch 10/100\n",
      "3260/3260 [==============================] - 0s 40us/sample - loss: 41.9512 - accuracy: 0.5043\n",
      "Epoch 11/100\n",
      "3260/3260 [==============================] - 0s 43us/sample - loss: 36.2800 - accuracy: 0.5086\n",
      "Epoch 12/100\n",
      "3260/3260 [==============================] - 0s 45us/sample - loss: 43.5366 - accuracy: 0.5067\n",
      "Epoch 13/100\n",
      "3260/3260 [==============================] - 0s 42us/sample - loss: 32.9652 - accuracy: 0.5141\n",
      "Epoch 14/100\n",
      "3260/3260 [==============================] - 0s 42us/sample - loss: 54.4727 - accuracy: 0.5178\n",
      "Epoch 15/100\n",
      "3260/3260 [==============================] - 0s 42us/sample - loss: 27.9595 - accuracy: 0.5255\n",
      "Epoch 16/100\n",
      "3260/3260 [==============================] - 0s 45us/sample - loss: 23.3592 - accuracy: 0.5196\n",
      "Epoch 17/100\n",
      "3260/3260 [==============================] - 0s 44us/sample - loss: 31.4174 - accuracy: 0.5028\n",
      "Epoch 18/100\n",
      "3260/3260 [==============================] - 0s 42us/sample - loss: 29.1575 - accuracy: 0.5129\n",
      "Epoch 19/100\n",
      "3260/3260 [==============================] - 0s 42us/sample - loss: 32.2429 - accuracy: 0.5202\n",
      "Epoch 20/100\n",
      "3260/3260 [==============================] - 0s 44us/sample - loss: 26.5122 - accuracy: 0.5163\n",
      "Epoch 21/100\n",
      "3260/3260 [==============================] - 0s 41us/sample - loss: 25.0492 - accuracy: 0.5166\n",
      "Epoch 22/100\n",
      "3260/3260 [==============================] - 0s 41us/sample - loss: 34.2972 - accuracy: 0.5129\n",
      "Epoch 23/100\n",
      "3260/3260 [==============================] - 0s 44us/sample - loss: 37.1519 - accuracy: 0.50430s - loss: 34.5525 - accuracy: 0.51\n",
      "Epoch 24/100\n",
      "3260/3260 [==============================] - 0s 40us/sample - loss: 30.2282 - accuracy: 0.5113\n",
      "Epoch 25/100\n",
      "3260/3260 [==============================] - 0s 41us/sample - loss: 22.5547 - accuracy: 0.5117\n",
      "Epoch 26/100\n",
      "3260/3260 [==============================] - 0s 42us/sample - loss: 43.0212 - accuracy: 0.5067\n",
      "Epoch 27/100\n",
      "3260/3260 [==============================] - 0s 41us/sample - loss: 38.4344 - accuracy: 0.5074\n",
      "Epoch 28/100\n",
      "3260/3260 [==============================] - 0s 42us/sample - loss: 48.0492 - accuracy: 0.5067\n",
      "Epoch 29/100\n",
      "3260/3260 [==============================] - 0s 42us/sample - loss: 41.9127 - accuracy: 0.5040\n",
      "Epoch 30/100\n",
      "3260/3260 [==============================] - 0s 42us/sample - loss: 45.3705 - accuracy: 0.51410s - loss: 48.7659 - accuracy: 0.505\n",
      "Epoch 31/100\n",
      "3260/3260 [==============================] - 0s 43us/sample - loss: 24.6804 - accuracy: 0.5215\n",
      "Epoch 32/100\n",
      "3260/3260 [==============================] - 0s 41us/sample - loss: 35.1985 - accuracy: 0.5095\n",
      "Epoch 33/100\n",
      "3260/3260 [==============================] - 0s 42us/sample - loss: 31.4589 - accuracy: 0.5282\n",
      "Epoch 34/100\n",
      "3260/3260 [==============================] - 0s 41us/sample - loss: 24.8696 - accuracy: 0.5218\n",
      "Epoch 35/100\n",
      "3260/3260 [==============================] - 0s 46us/sample - loss: 39.0086 - accuracy: 0.5074\n",
      "Epoch 36/100\n",
      "3260/3260 [==============================] - 0s 51us/sample - loss: 23.5909 - accuracy: 0.5304\n",
      "Epoch 37/100\n",
      "3260/3260 [==============================] - 0s 42us/sample - loss: 39.9113 - accuracy: 0.5117\n",
      "Epoch 38/100\n",
      "3260/3260 [==============================] - 0s 43us/sample - loss: 24.0865 - accuracy: 0.5135\n",
      "Epoch 39/100\n",
      "3260/3260 [==============================] - 0s 42us/sample - loss: 21.8720 - accuracy: 0.5172\n",
      "Epoch 40/100\n",
      "3260/3260 [==============================] - 0s 43us/sample - loss: 30.2316 - accuracy: 0.5089\n",
      "Epoch 41/100\n",
      "3260/3260 [==============================] - 0s 42us/sample - loss: 16.7616 - accuracy: 0.5224\n",
      "Epoch 42/100\n",
      "3260/3260 [==============================] - 0s 52us/sample - loss: 30.7030 - accuracy: 0.5092\n",
      "Epoch 43/100\n",
      "3260/3260 [==============================] - 0s 56us/sample - loss: 26.5731 - accuracy: 0.5199\n",
      "Epoch 44/100\n",
      "3260/3260 [==============================] - 0s 42us/sample - loss: 21.5983 - accuracy: 0.5239\n",
      "Epoch 45/100\n",
      "3260/3260 [==============================] - 0s 41us/sample - loss: 20.6496 - accuracy: 0.5227\n",
      "Epoch 46/100\n",
      "3260/3260 [==============================] - 0s 42us/sample - loss: 32.6165 - accuracy: 0.5316\n",
      "Epoch 47/100\n",
      "3260/3260 [==============================] - 0s 43us/sample - loss: 38.7384 - accuracy: 0.5196\n",
      "Epoch 48/100\n",
      "3260/3260 [==============================] - 0s 41us/sample - loss: 28.9792 - accuracy: 0.5239\n",
      "Epoch 49/100\n",
      "3260/3260 [==============================] - 0s 42us/sample - loss: 27.5902 - accuracy: 0.5049\n",
      "Epoch 50/100\n",
      "3260/3260 [==============================] - 0s 42us/sample - loss: 25.5734 - accuracy: 0.5123\n",
      "Epoch 51/100\n",
      "3260/3260 [==============================] - 0s 42us/sample - loss: 30.4515 - accuracy: 0.5230\n",
      "Epoch 52/100\n",
      "3260/3260 [==============================] - 0s 43us/sample - loss: 23.0777 - accuracy: 0.5196\n",
      "Epoch 53/100\n",
      "3260/3260 [==============================] - 0s 41us/sample - loss: 28.3783 - accuracy: 0.5123\n",
      "Epoch 54/100\n",
      "3260/3260 [==============================] - 0s 43us/sample - loss: 31.1290 - accuracy: 0.5288\n",
      "Epoch 55/100\n",
      "3260/3260 [==============================] - 0s 41us/sample - loss: 24.7348 - accuracy: 0.5166\n",
      "Epoch 56/100\n",
      "3260/3260 [==============================] - 0s 40us/sample - loss: 31.9052 - accuracy: 0.53440s - loss: 26.5414 - accuracy: 0.538\n",
      "Epoch 57/100\n",
      "3260/3260 [==============================] - 0s 40us/sample - loss: 40.6473 - accuracy: 0.5135\n",
      "Epoch 58/100\n",
      "3260/3260 [==============================] - 0s 41us/sample - loss: 30.0451 - accuracy: 0.5206\n",
      "Epoch 59/100\n",
      "3260/3260 [==============================] - 0s 41us/sample - loss: 25.2150 - accuracy: 0.5233\n",
      "Epoch 60/100\n",
      "3260/3260 [==============================] - 0s 44us/sample - loss: 24.0062 - accuracy: 0.5347\n",
      "Epoch 61/100\n",
      "3260/3260 [==============================] - 0s 42us/sample - loss: 27.3936 - accuracy: 0.5113\n",
      "Epoch 62/100\n",
      "3260/3260 [==============================] - 0s 41us/sample - loss: 23.8799 - accuracy: 0.5086\n",
      "Epoch 63/100\n",
      "3260/3260 [==============================] - 0s 41us/sample - loss: 40.2427 - accuracy: 0.5184\n",
      "Epoch 64/100\n",
      "3260/3260 [==============================] - 0s 41us/sample - loss: 22.5118 - accuracy: 0.5258\n",
      "Epoch 65/100\n",
      "3260/3260 [==============================] - 0s 44us/sample - loss: 30.8865 - accuracy: 0.53370s - loss: 16.0688 - accuracy: 0.53\n",
      "Epoch 66/100\n",
      "3260/3260 [==============================] - 0s 43us/sample - loss: 26.9349 - accuracy: 0.5187\n",
      "Epoch 67/100\n",
      "3260/3260 [==============================] - 0s 40us/sample - loss: 22.1278 - accuracy: 0.4936\n",
      "Epoch 68/100\n",
      "3260/3260 [==============================] - 0s 41us/sample - loss: 26.6697 - accuracy: 0.5144\n",
      "Epoch 69/100\n",
      "3260/3260 [==============================] - 0s 41us/sample - loss: 22.3272 - accuracy: 0.5276\n",
      "Epoch 70/100\n",
      "3260/3260 [==============================] - 0s 41us/sample - loss: 23.1842 - accuracy: 0.5236\n",
      "Epoch 71/100\n",
      "3260/3260 [==============================] - 0s 41us/sample - loss: 37.5704 - accuracy: 0.5144\n",
      "Epoch 72/100\n",
      "3260/3260 [==============================] - 0s 41us/sample - loss: 26.1770 - accuracy: 0.5175\n",
      "Epoch 73/100\n",
      "3260/3260 [==============================] - 0s 58us/sample - loss: 19.5649 - accuracy: 0.5123\n",
      "Epoch 74/100\n",
      "3260/3260 [==============================] - 0s 45us/sample - loss: 25.7768 - accuracy: 0.5166\n",
      "Epoch 75/100\n",
      "3260/3260 [==============================] - 0s 39us/sample - loss: 35.0141 - accuracy: 0.5160\n",
      "Epoch 76/100\n",
      "3260/3260 [==============================] - 0s 41us/sample - loss: 24.3064 - accuracy: 0.5101\n",
      "Epoch 77/100\n",
      "3260/3260 [==============================] - 0s 38us/sample - loss: 24.3839 - accuracy: 0.5344\n",
      "Epoch 78/100\n",
      "3260/3260 [==============================] - 0s 39us/sample - loss: 25.1936 - accuracy: 0.5181\n",
      "Epoch 79/100\n",
      "3260/3260 [==============================] - 0s 39us/sample - loss: 20.3643 - accuracy: 0.5252\n",
      "Epoch 80/100\n",
      "3260/3260 [==============================] - ETA: 0s - loss: 15.4051 - accuracy: 0.532 - 0s 50us/sample - loss: 15.1124 - accuracy: 0.5340\n",
      "Epoch 81/100\n",
      "3260/3260 [==============================] - 0s 48us/sample - loss: 20.1565 - accuracy: 0.5252\n",
      "Epoch 82/100\n",
      "3260/3260 [==============================] - 0s 39us/sample - loss: 27.1337 - accuracy: 0.5347\n",
      "Epoch 83/100\n",
      "3260/3260 [==============================] - 0s 40us/sample - loss: 26.0000 - accuracy: 0.5276\n",
      "Epoch 84/100\n",
      "3260/3260 [==============================] - 0s 42us/sample - loss: 23.5714 - accuracy: 0.5141\n",
      "Epoch 85/100\n",
      "3260/3260 [==============================] - 0s 41us/sample - loss: 22.8607 - accuracy: 0.5202\n",
      "Epoch 86/100\n",
      "3260/3260 [==============================] - 0s 39us/sample - loss: 19.2054 - accuracy: 0.5420\n",
      "Epoch 87/100\n",
      "3260/3260 [==============================] - 0s 39us/sample - loss: 21.1773 - accuracy: 0.5307\n",
      "Epoch 88/100\n",
      "3260/3260 [==============================] - 0s 39us/sample - loss: 18.5249 - accuracy: 0.5294\n",
      "Epoch 89/100\n",
      "3260/3260 [==============================] - 0s 41us/sample - loss: 21.9561 - accuracy: 0.5353\n",
      "Epoch 90/100\n",
      "3260/3260 [==============================] - 0s 40us/sample - loss: 19.3558 - accuracy: 0.5104\n",
      "Epoch 91/100\n",
      "3260/3260 [==============================] - 0s 40us/sample - loss: 16.4636 - accuracy: 0.5350\n",
      "Epoch 92/100\n",
      "3260/3260 [==============================] - 0s 40us/sample - loss: 21.5210 - accuracy: 0.5294\n",
      "Epoch 93/100\n",
      "3260/3260 [==============================] - 0s 41us/sample - loss: 23.8462 - accuracy: 0.52450s - loss: 20.9995 - accuracy: 0.528\n",
      "Epoch 94/100\n",
      "3260/3260 [==============================] - 0s 39us/sample - loss: 33.9991 - accuracy: 0.5230\n",
      "Epoch 95/100\n",
      "3260/3260 [==============================] - 0s 39us/sample - loss: 33.9870 - accuracy: 0.5092\n",
      "Epoch 96/100\n",
      "3260/3260 [==============================] - 0s 40us/sample - loss: 21.1600 - accuracy: 0.5153\n",
      "Epoch 97/100\n",
      "3260/3260 [==============================] - 0s 40us/sample - loss: 21.0154 - accuracy: 0.5190\n",
      "Epoch 98/100\n",
      "3260/3260 [==============================] - 0s 40us/sample - loss: 30.2374 - accuracy: 0.5282\n",
      "Epoch 99/100\n",
      "3260/3260 [==============================] - 0s 39us/sample - loss: 25.1188 - accuracy: 0.5334\n",
      "Epoch 100/100\n",
      "3260/3260 [==============================] - 0s 40us/sample - loss: 32.1955 - accuracy: 0.5371\n",
      "2000/2000 [==============================] - 0s 73us/sample - loss: 10.9774 - accuracy: 0.4770\n",
      "[10.977389610290528, 0.477]\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.40      0.55      1593\n",
      "           1       0.25      0.77      0.38       407\n",
      "\n",
      "    accuracy                           0.48      2000\n",
      "   macro avg       0.56      0.59      0.46      2000\n",
      "weighted avg       0.75      0.48      0.51      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x_train,y_train=get_train_batch(df3_class_0,df3_class_1,3260,4890)\n",
    "y_preds_3 = ANN(x_train, y_train, x_test, y_test, 'binary_crossentropy', -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3110 samples\n",
      "Epoch 1/100\n",
      "3110/3110 [==============================] - 1s 187us/sample - loss: 1874.4513 - accuracy: 0.5087\n",
      "Epoch 2/100\n",
      "3110/3110 [==============================] - 0s 41us/sample - loss: 202.1828 - accuracy: 0.5068\n",
      "Epoch 3/100\n",
      "3110/3110 [==============================] - 0s 42us/sample - loss: 95.3875 - accuracy: 0.5186\n",
      "Epoch 4/100\n",
      "3110/3110 [==============================] - 0s 42us/sample - loss: 62.7816 - accuracy: 0.5006\n",
      "Epoch 5/100\n",
      "3110/3110 [==============================] - 0s 43us/sample - loss: 65.4129 - accuracy: 0.5199\n",
      "Epoch 6/100\n",
      "3110/3110 [==============================] - 0s 43us/sample - loss: 57.9617 - accuracy: 0.5260\n",
      "Epoch 7/100\n",
      "3110/3110 [==============================] - 0s 45us/sample - loss: 53.3252 - accuracy: 0.5064\n",
      "Epoch 8/100\n",
      "3110/3110 [==============================] - 0s 41us/sample - loss: 43.0337 - accuracy: 0.5222\n",
      "Epoch 9/100\n",
      "3110/3110 [==============================] - 0s 43us/sample - loss: 45.0671 - accuracy: 0.5199\n",
      "Epoch 10/100\n",
      "3110/3110 [==============================] - 0s 42us/sample - loss: 39.7909 - accuracy: 0.5035\n",
      "Epoch 11/100\n",
      "3110/3110 [==============================] - 0s 42us/sample - loss: 43.8843 - accuracy: 0.5180\n",
      "Epoch 12/100\n",
      "3110/3110 [==============================] - 0s 42us/sample - loss: 43.2162 - accuracy: 0.5109\n",
      "Epoch 13/100\n",
      "3110/3110 [==============================] - 0s 44us/sample - loss: 44.8791 - accuracy: 0.5186\n",
      "Epoch 14/100\n",
      "3110/3110 [==============================] - 0s 42us/sample - loss: 53.3663 - accuracy: 0.5122\n",
      "Epoch 15/100\n",
      "3110/3110 [==============================] - 0s 43us/sample - loss: 40.9496 - accuracy: 0.5141\n",
      "Epoch 16/100\n",
      "3110/3110 [==============================] - 0s 42us/sample - loss: 46.6911 - accuracy: 0.5206\n",
      "Epoch 17/100\n",
      "3110/3110 [==============================] - 0s 43us/sample - loss: 34.8287 - accuracy: 0.5296\n",
      "Epoch 18/100\n",
      "3110/3110 [==============================] - 0s 42us/sample - loss: 37.8283 - accuracy: 0.5260\n",
      "Epoch 19/100\n",
      "3110/3110 [==============================] - 0s 42us/sample - loss: 38.9233 - accuracy: 0.5264\n",
      "Epoch 20/100\n",
      "3110/3110 [==============================] - 0s 42us/sample - loss: 31.8838 - accuracy: 0.5322\n",
      "Epoch 21/100\n",
      "3110/3110 [==============================] - 0s 52us/sample - loss: 54.6143 - accuracy: 0.5145\n",
      "Epoch 22/100\n",
      "3110/3110 [==============================] - 0s 43us/sample - loss: 45.5986 - accuracy: 0.5457\n",
      "Epoch 23/100\n",
      "3110/3110 [==============================] - 0s 42us/sample - loss: 36.4739 - accuracy: 0.5103\n",
      "Epoch 24/100\n",
      "3110/3110 [==============================] - 0s 43us/sample - loss: 55.6754 - accuracy: 0.5154\n",
      "Epoch 25/100\n",
      "3110/3110 [==============================] - 0s 49us/sample - loss: 37.1792 - accuracy: 0.5177\n",
      "Epoch 26/100\n",
      "3110/3110 [==============================] - 0s 44us/sample - loss: 34.7812 - accuracy: 0.5270\n",
      "Epoch 27/100\n",
      "3110/3110 [==============================] - 0s 42us/sample - loss: 38.4417 - accuracy: 0.5299\n",
      "Epoch 28/100\n",
      "3110/3110 [==============================] - 0s 42us/sample - loss: 40.8230 - accuracy: 0.5267\n",
      "Epoch 29/100\n",
      "3110/3110 [==============================] - 0s 42us/sample - loss: 26.2127 - accuracy: 0.5209\n",
      "Epoch 30/100\n",
      "3110/3110 [==============================] - 0s 42us/sample - loss: 30.4147 - accuracy: 0.5244\n",
      "Epoch 31/100\n",
      "3110/3110 [==============================] - 0s 42us/sample - loss: 41.5848 - accuracy: 0.5122\n",
      "Epoch 32/100\n",
      "3110/3110 [==============================] - 0s 44us/sample - loss: 38.1796 - accuracy: 0.5309\n",
      "Epoch 33/100\n",
      "3110/3110 [==============================] - 0s 54us/sample - loss: 29.8738 - accuracy: 0.5167\n",
      "Epoch 34/100\n",
      "3110/3110 [==============================] - 0s 48us/sample - loss: 32.8089 - accuracy: 0.5277\n",
      "Epoch 35/100\n",
      "3110/3110 [==============================] - 0s 42us/sample - loss: 40.3422 - accuracy: 0.5267\n",
      "Epoch 36/100\n",
      "3110/3110 [==============================] - 0s 43us/sample - loss: 32.6397 - accuracy: 0.5193\n",
      "Epoch 37/100\n",
      "3110/3110 [==============================] - 0s 44us/sample - loss: 45.0405 - accuracy: 0.5344\n",
      "Epoch 38/100\n",
      "3110/3110 [==============================] - 0s 43us/sample - loss: 30.9901 - accuracy: 0.5296\n",
      "Epoch 39/100\n",
      "3110/3110 [==============================] - 0s 43us/sample - loss: 32.2220 - accuracy: 0.5177\n",
      "Epoch 40/100\n",
      "3110/3110 [==============================] - 0s 42us/sample - loss: 24.8701 - accuracy: 0.5392\n",
      "Epoch 41/100\n",
      "3110/3110 [==============================] - 0s 44us/sample - loss: 28.4627 - accuracy: 0.5254\n",
      "Epoch 42/100\n",
      "3110/3110 [==============================] - 0s 43us/sample - loss: 37.9278 - accuracy: 0.5379\n",
      "Epoch 43/100\n",
      "3110/3110 [==============================] - 0s 42us/sample - loss: 40.3121 - accuracy: 0.5305\n",
      "Epoch 44/100\n",
      "3110/3110 [==============================] - 0s 44us/sample - loss: 28.9214 - accuracy: 0.5113\n",
      "Epoch 45/100\n",
      "3110/3110 [==============================] - 0s 42us/sample - loss: 51.0489 - accuracy: 0.4981\n",
      "Epoch 46/100\n",
      "3110/3110 [==============================] - 0s 43us/sample - loss: 32.4954 - accuracy: 0.5244\n",
      "Epoch 47/100\n",
      "3110/3110 [==============================] - 0s 42us/sample - loss: 22.6816 - accuracy: 0.5264\n",
      "Epoch 48/100\n",
      "3110/3110 [==============================] - 0s 42us/sample - loss: 29.4835 - accuracy: 0.5367\n",
      "Epoch 49/100\n",
      "3110/3110 [==============================] - 0s 42us/sample - loss: 35.3859 - accuracy: 0.5183\n",
      "Epoch 50/100\n",
      "3110/3110 [==============================] - 0s 42us/sample - loss: 26.5255 - accuracy: 0.5331\n",
      "Epoch 51/100\n",
      "3110/3110 [==============================] - 0s 42us/sample - loss: 32.1134 - accuracy: 0.5344\n",
      "Epoch 52/100\n",
      "3110/3110 [==============================] - 0s 44us/sample - loss: 27.5260 - accuracy: 0.5248\n",
      "Epoch 53/100\n",
      "3110/3110 [==============================] - 0s 42us/sample - loss: 29.2277 - accuracy: 0.5277\n",
      "Epoch 54/100\n",
      "3110/3110 [==============================] - 0s 41us/sample - loss: 39.8742 - accuracy: 0.5334\n",
      "Epoch 55/100\n",
      "3110/3110 [==============================] - 0s 41us/sample - loss: 35.2816 - accuracy: 0.51770s - loss: 39.2393 - accuracy: 0.517\n",
      "Epoch 56/100\n",
      "3110/3110 [==============================] - 0s 44us/sample - loss: 33.7705 - accuracy: 0.5331\n",
      "Epoch 57/100\n",
      "3110/3110 [==============================] - 0s 42us/sample - loss: 26.7934 - accuracy: 0.5199\n",
      "Epoch 58/100\n",
      "3110/3110 [==============================] - 0s 41us/sample - loss: 41.5857 - accuracy: 0.5289\n",
      "Epoch 59/100\n",
      "3110/3110 [==============================] - 0s 42us/sample - loss: 29.5716 - accuracy: 0.5293\n",
      "Epoch 60/100\n",
      "3110/3110 [==============================] - 0s 42us/sample - loss: 25.9412 - accuracy: 0.5376\n",
      "Epoch 61/100\n",
      "3110/3110 [==============================] - 0s 42us/sample - loss: 34.1145 - accuracy: 0.52250s - loss: 31.3588 - accuracy: 0.51\n",
      "Epoch 62/100\n",
      "3110/3110 [==============================] - 0s 41us/sample - loss: 29.8135 - accuracy: 0.5235\n",
      "Epoch 63/100\n",
      "3110/3110 [==============================] - 0s 47us/sample - loss: 27.9725 - accuracy: 0.5199\n",
      "Epoch 64/100\n",
      "3110/3110 [==============================] - 0s 48us/sample - loss: 25.6777 - accuracy: 0.5241\n",
      "Epoch 65/100\n",
      "3110/3110 [==============================] - 0s 42us/sample - loss: 37.5671 - accuracy: 0.5273\n",
      "Epoch 66/100\n",
      "3110/3110 [==============================] - 0s 40us/sample - loss: 26.8047 - accuracy: 0.5309\n",
      "Epoch 67/100\n",
      "3110/3110 [==============================] - ETA: 0s - loss: 29.4998 - accuracy: 0.525 - 0s 43us/sample - loss: 36.8423 - accuracy: 0.5212\n",
      "Epoch 68/100\n",
      "3110/3110 [==============================] - 0s 42us/sample - loss: 45.1997 - accuracy: 0.5193\n",
      "Epoch 69/100\n",
      "3110/3110 [==============================] - 0s 41us/sample - loss: 27.4279 - accuracy: 0.5203\n",
      "Epoch 70/100\n",
      "3110/3110 [==============================] - 0s 42us/sample - loss: 18.3177 - accuracy: 0.5399\n",
      "Epoch 71/100\n",
      "3110/3110 [==============================] - 0s 41us/sample - loss: 40.5698 - accuracy: 0.5283\n",
      "Epoch 72/100\n",
      "3110/3110 [==============================] - 0s 52us/sample - loss: 38.7886 - accuracy: 0.5318\n",
      "Epoch 73/100\n",
      "3110/3110 [==============================] - 0s 49us/sample - loss: 26.2341 - accuracy: 0.5389\n",
      "Epoch 74/100\n",
      "3110/3110 [==============================] - 0s 41us/sample - loss: 32.5534 - accuracy: 0.5196\n",
      "Epoch 75/100\n",
      "3110/3110 [==============================] - 0s 41us/sample - loss: 30.4271 - accuracy: 0.5360\n",
      "Epoch 76/100\n",
      "3110/3110 [==============================] - 0s 39us/sample - loss: 29.5547 - accuracy: 0.5350\n",
      "Epoch 77/100\n",
      "3110/3110 [==============================] - 0s 40us/sample - loss: 31.9954 - accuracy: 0.5116\n",
      "Epoch 78/100\n",
      "3110/3110 [==============================] - 0s 39us/sample - loss: 32.2977 - accuracy: 0.5309\n",
      "Epoch 79/100\n",
      "3110/3110 [==============================] - 0s 40us/sample - loss: 35.8823 - accuracy: 0.5305\n",
      "Epoch 80/100\n",
      "3110/3110 [==============================] - 0s 39us/sample - loss: 30.1373 - accuracy: 0.5376\n",
      "Epoch 81/100\n",
      "3110/3110 [==============================] - 0s 39us/sample - loss: 34.5746 - accuracy: 0.5299\n",
      "Epoch 82/100\n",
      "3110/3110 [==============================] - 0s 42us/sample - loss: 32.6595 - accuracy: 0.5367\n",
      "Epoch 83/100\n",
      "3110/3110 [==============================] - 0s 39us/sample - loss: 24.1238 - accuracy: 0.5341\n",
      "Epoch 84/100\n",
      "3110/3110 [==============================] - 0s 40us/sample - loss: 34.5053 - accuracy: 0.5154\n",
      "Epoch 85/100\n",
      "3110/3110 [==============================] - 0s 40us/sample - loss: 38.8737 - accuracy: 0.5251\n",
      "Epoch 86/100\n",
      "3110/3110 [==============================] - 0s 39us/sample - loss: 29.1686 - accuracy: 0.5264\n",
      "Epoch 87/100\n",
      "3110/3110 [==============================] - 0s 40us/sample - loss: 37.9374 - accuracy: 0.5363\n",
      "Epoch 88/100\n",
      "3110/3110 [==============================] - 0s 39us/sample - loss: 36.9348 - accuracy: 0.5061\n",
      "Epoch 89/100\n",
      "3110/3110 [==============================] - 0s 41us/sample - loss: 30.6279 - accuracy: 0.53890s - loss: 49.2410 - accuracy: 0.537\n",
      "Epoch 90/100\n",
      "3110/3110 [==============================] - 0s 41us/sample - loss: 26.9858 - accuracy: 0.5315\n",
      "Epoch 91/100\n",
      "3110/3110 [==============================] - 0s 39us/sample - loss: 21.1901 - accuracy: 0.5389\n",
      "Epoch 92/100\n",
      "3110/3110 [==============================] - 0s 39us/sample - loss: 42.8075 - accuracy: 0.5219\n",
      "Epoch 93/100\n",
      "3110/3110 [==============================] - 0s 40us/sample - loss: 28.6389 - accuracy: 0.5363\n",
      "Epoch 94/100\n",
      "3110/3110 [==============================] - 0s 39us/sample - loss: 40.4366 - accuracy: 0.5196\n",
      "Epoch 95/100\n",
      "3110/3110 [==============================] - 0s 39us/sample - loss: 32.4959 - accuracy: 0.5267\n",
      "Epoch 96/100\n",
      "3110/3110 [==============================] - 0s 39us/sample - loss: 30.6528 - accuracy: 0.5457\n",
      "Epoch 97/100\n",
      "3110/3110 [==============================] - 0s 40us/sample - loss: 24.5294 - accuracy: 0.5318\n",
      "Epoch 98/100\n",
      "3110/3110 [==============================] - 0s 40us/sample - loss: 37.7576 - accuracy: 0.5338\n",
      "Epoch 99/100\n",
      "3110/3110 [==============================] - 0s 38us/sample - loss: 20.7759 - accuracy: 0.5415\n",
      "Epoch 100/100\n",
      "3110/3110 [==============================] - 0s 40us/sample - loss: 44.1154 - accuracy: 0.5260\n",
      "2000/2000 [==============================] - 0s 74us/sample - loss: 42.3848 - accuracy: 0.2775\n",
      "[42.38475274658203, 0.2775]\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.11      0.20      1593\n",
      "           1       0.21      0.91      0.34       407\n",
      "\n",
      "    accuracy                           0.28      2000\n",
      "   macro avg       0.52      0.51      0.27      2000\n",
      "weighted avg       0.71      0.28      0.23      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x_train,y_train=get_train_batch(df3_class_0,df3_class_1,4890,6370)\n",
    "y_preds_4 = ANN(x_train, y_train, x_test, y_test, 'binary_crossentropy', -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 2000, 2000, 2000)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_preds_1),len(y_preds_2),len(y_preds_3),len(y_preds_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_final=y_preds_1.copy()\n",
    "\n",
    "for i in range(len(y_pred_final)):\n",
    "    \n",
    "    n_ones=y_preds_1[i]+y_preds_2[i]+y_preds_3[i]\n",
    "    if n_ones>1:\n",
    "        y_pred_final[i]=1\n",
    "    else:\n",
    "        y_pred_final[i]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.06      0.12      1593\n",
      "           1       0.21      0.95      0.34       407\n",
      "\n",
      "    accuracy                           0.24      2000\n",
      "   macro avg       0.52      0.51      0.23      2000\n",
      "weighted avg       0.71      0.24      0.16      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,y_pred_final))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "compare to all methods method 1 give the best results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
